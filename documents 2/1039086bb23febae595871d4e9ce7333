<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Stream processing,Articles with unsourced statements since June 2008,Parallel computing,2005,AMD,API,AT&amp;T,AT&amp;T Labs,ATI,ATI Technologies,AccelerEyes" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Stream_processing&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Stream_processing&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Stream processing - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Stream_processing";
		var wgTitle = "Stream processing";
		var wgAction = "view";
		var wgArticleId = "2786727";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 272820101;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
<style type="text/css">/*<![CDATA[*/
.source-c {line-height: normal;}
.source-c li, .source-c pre {
	line-height: normal; border: 0px none white;
}
/**
 * GeSHi Dynamically Generated Stylesheet
 * --------------------------------------
 * Dynamically generated stylesheet for c
 * CSS class: source-c, CSS id: 
 * GeSHi (C) 2004 - 2007 Nigel McNie (http://qbnz.com/highlighter)
 */
.source-c .de1, .source-c .de2 {font-family: 'Courier New', Courier, monospace; font-weight: normal;}
.source-c  {}
.source-c .head {}
.source-c .foot {}
.source-c .imp {font-weight: bold; color: red;}
.source-c .ln-xtra {color: #cc0; background-color: #ffc;}
.source-c li {font-family: 'Courier New', Courier, monospace; color: black; font-weight: normal; font-style: normal;}
.source-c li.li2 {font-weight: bold;}
.source-c .kw1 {color: #b1b100;}
.source-c .kw2 {color: #000000; font-weight: bold;}
.source-c .kw3 {color: #000066;}
.source-c .kw4 {color: #993333;}
.source-c .co1 {color: #808080; font-style: italic;}
.source-c .co2 {color: #339933;}
.source-c .coMULTI {color: #808080; font-style: italic;}
.source-c .es0 {color: #000099; font-weight: bold;}
.source-c .br0 {color: #66cc66;}
.source-c .st0 {color: #ff0000;}
.source-c .nu0 {color: #cc66cc;}
.source-c .me1 {color: #202020;}
.source-c .me2 {color: #202020;}

/*]]>*/
</style>
<style type="text/css">/*<![CDATA[*/
@import "/w/index.php?title=MediaWiki:Geshi.css&usemsgcache=yes&action=raw&ctype=text/css&smaxage=2678400";
/*]]>*/
</style>		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Stream_processing skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Stream processing</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="dablink">For other uses, see <a href="/wiki/Event_Stream_Processing" title="Event Stream Processing">Event Stream Processing</a>.</div>
<table class="metadata plainlinks ambox ambox-move" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Merge-arrow.svg" class="image" title="Merge arrow"><img alt="Merge arrow" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Merge-arrow.svg/50px-Merge-arrow.svg.png" width="50" height="20" border="0" /></a></div>
</td>
<td class="mbox-text" style="">It has been suggested that this article or section be <a href="/wiki/Wikipedia:Merging_and_moving_pages" title="Wikipedia:Merging and moving pages" class="mw-redirect">merged</a> into <i><a href="/wiki/Vector_processor" title="Vector processor">Vector processor</a></i>. (<a href="/wiki/Talk:Vector_processor" title="Talk:Vector processor">Discuss</a>)</td>
</tr>
</table>
<p><b>Stream processing</b> is a <a href="/wiki/Computer_programming" title="Computer programming">computer programming</a> paradigm, related to <a href="/wiki/SIMD" title="SIMD">SIMD</a>, that allows some applications to more easily exploit a limited form of <a href="/wiki/Parallel_computing" title="Parallel computing">parallel processing</a>. Such applications can use multiple computational units, such as the <a href="/wiki/Floating_point_unit" title="Floating point unit" class="mw-redirect">floating point units</a> on a <a href="/wiki/Graphics_processing_unit" title="Graphics processing unit">GPU</a>, without explicitly managing allocation, synchronization, or communication among those units.</p>
<p>The stream processing paradigm simplifies parallel software and hardware by restricting the parallel computation that can be performed. Given a set of data (a <i>stream</i>), a series of operations (<i>kernel functions</i>) are applied to each element in the stream. <i>Uniform streaming</i>, where one kernel function is applied to all elements in the stream, is typical. Kernel functions are usually <a href="/wiki/Pipeline_(computing)" title="Pipeline (computing)">pipelined</a>, and local on-chip memory is reused to minimize external memory bandwidth. Since the kernel and stream abstractions expose data dependencies, compiler tools can fully automate and optimize on-chip management tasks. Stream processing hardware can use <a href="/wiki/Scoreboarding" title="Scoreboarding">scoreboarding</a>, for example, to launch <a href="/wiki/Direct_memory_access" title="Direct memory access">DMAs</a> at runtime, when dependencies become known. The elimination of manual DMA management reduces software complexity, and the elimination of hardware caches reduces the amount of die area not dedicated to computational units such as <a href="/wiki/Arithmetic_logic_unit" title="Arithmetic logic unit">ALUs</a>.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Applications"><span class="tocnumber">1</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1"><a href="#Comparison_to_prior_parallel_paradigms"><span class="tocnumber">2</span> <span class="toctext">Comparison to prior parallel paradigms</span></a>
<ul>
<li class="toclevel-2"><a href="#Conventional.2C_sequential_paradigm"><span class="tocnumber">2.1</span> <span class="toctext">Conventional, sequential paradigm</span></a></li>
<li class="toclevel-2"><a href="#Parallel_SIMD_paradigm.2C_packed_registers_.28SWAR.29"><span class="tocnumber">2.2</span> <span class="toctext">Parallel SIMD paradigm, packed registers (SWAR)</span></a></li>
<li class="toclevel-2"><a href="#Parallel_Stream_paradigm_.28SIMD.2FMIMD.29"><span class="tocnumber">2.3</span> <span class="toctext">Parallel Stream paradigm (SIMD/MIMD)</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Stream_processing_considerations"><span class="tocnumber">3</span> <span class="toctext">Stream processing considerations</span></a>
<ul>
<li class="toclevel-2"><a href="#Data_dependencies_and_parallelism"><span class="tocnumber">3.1</span> <span class="toctext">Data dependencies and parallelism</span></a></li>
<li class="toclevel-2"><a href="#Programming_model_notes"><span class="tocnumber">3.2</span> <span class="toctext">Programming model notes</span></a></li>
<li class="toclevel-2"><a href="#Generic_processor_architecture"><span class="tocnumber">3.3</span> <span class="toctext">Generic processor architecture</span></a></li>
<li class="toclevel-2"><a href="#Hardware-in-the-loop_issues"><span class="tocnumber">3.4</span> <span class="toctext">Hardware-in-the-loop issues</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Interesting_Stream_Processors"><span class="tocnumber">4</span> <span class="toctext">Interesting Stream Processors</span></a></li>
<li class="toclevel-1"><a href="#Stream_Programming_Languages"><span class="tocnumber">5</span> <span class="toctext">Stream Programming Languages</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#Notes"><span class="tocnumber">8</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">9</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Applications" id="Applications"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=1" title="Edit section: Applications">edit</a>]</span> <span class="mw-headline">Applications</span></h2>
<p>Stream processing is essentially a compromise, driven by a data-centric model that works very well for traditional DSP or GPU-type applications (such as image, video and digital signal processing) but less so for general purpose processing with more randomized data access (such as databases). By sacrificing some flexibility in the model, the implications allow easier, faster and more efficient execution. Depending on the context, <a href="/wiki/Central_processing_unit" title="Central processing unit">processor</a> design may be tuned for maximum efficiency or a trade-off for flexibility.</p>
<p>Stream processing is especially suitable for applications that exhibit three application characteristics<sup class="noprint Template-Fact"><span title="This claim needs references to reliable sources&#160;since June 2008" style="white-space: nowrap;">[<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed">citation needed</a></i>]</span></sup>:</p>
<ul>
<li><b>Compute Intensity</b>, the number of arithmetic operations per I/O or global memory reference. In many signal processing applications today it is well over 50:1 and increasing with algorithmic complexity.</li>
<li><b>Data Parallelism</b> exists in a kernel if the same function is applied to all records of an input stream and a number of records can be processed simultaneously without waiting for results from previous records.</li>
<li><b>Data Locality</b> is a specific type of temporal locality common in signal and media processing applications where data is produced once, read once or twice later in the application, and never read again. Intermediate streams passed between kernels as well as intermediate data within kernel functions can capture this locality directly using the stream processing programming model.</li>
</ul>
<p><a name="Comparison_to_prior_parallel_paradigms" id="Comparison_to_prior_parallel_paradigms"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=2" title="Edit section: Comparison to prior parallel paradigms">edit</a>]</span> <span class="mw-headline">Comparison to prior parallel paradigms</span></h2>
<p>Basic computers started from a sequential execution paradigm. Traditional <a href="/wiki/Central_processing_unit" title="Central processing unit">CPUs</a> are <a href="/wiki/SISD" title="SISD">SISD</a> based, which means they conceptually perform only one operation at a time. As the computing needs of the world evolved, the amount of data to be managed increased very quickly. It was obvious that the sequential programming model could not cope with the increased need for processing power. Various efforts have been spent on finding alternative ways to perform massive amounts of computations but the only solution was to exploit some level of parallel execution. The result of those efforts was <a href="/wiki/SIMD" title="SIMD">SIMD</a>, a programming paradigm which allowed applying one instruction to multiple instances of (different) data. Most of the time, SIMD was being used in a <a href="/wiki/SWAR" title="SWAR">SWAR</a> environment. By using more complicated structures, one could also have <a href="/wiki/MIMD" title="MIMD">MIMD</a> parallelism.</p>
<p>Although those two paradigms were efficient, real-world implementations were plagued with limitations from memory alignment problems to synchronization issues and limited parallelism. Only few SIMD processors survived as stand-alone components; most were embedded in standard CPUs.</p>
<p>Consider a simple program adding up two arrays containing 100 4-component <a href="/wiki/Vector_(geometric)" title="Vector (geometric)" class="mw-redirect">vectors</a> (i.e. 400 numbers in total).</p>
<p><a name="Conventional.2C_sequential_paradigm" id="Conventional.2C_sequential_paradigm"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=3" title="Edit section: Conventional, sequential paradigm">edit</a>]</span> <span class="mw-headline">Conventional, sequential paradigm</span></h3>
<div dir="ltr" style="text-align: left;">
<pre class="source-c">
  <span class="kw1">for</span><span class="br0">(</span><span class="kw4">int</span> i = <span class="nu0">0</span>; i &lt; <span class="nu0">100</span> * <span class="nu0">4</span>; i++<span class="br0">)</span>
    result<span class="br0">[</span>i<span class="br0">]</span> = source0<span class="br0">[</span>i<span class="br0">]</span> + source1<span class="br0">[</span>i<span class="br0">]</span>;
</pre></div>
<p>This is the naive method that most computer science students would think of. Variations do exist (such as inner loops, structures and such) but they ultimately boil down to that.</p>
<p><a name="Parallel_SIMD_paradigm.2C_packed_registers_.28SWAR.29" id="Parallel_SIMD_paradigm.2C_packed_registers_.28SWAR.29"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=4" title="Edit section: Parallel SIMD paradigm, packed registers (SWAR)">edit</a>]</span> <span class="mw-headline">Parallel SIMD paradigm, packed registers (SWAR)</span></h3>
<div dir="ltr" style="text-align: left;">
<pre class="source-c">
 <span class="kw1">for</span><span class="br0">(</span><span class="kw4">int</span> el = <span class="nu0">0</span>; el &lt; <span class="nu0">100</span>; el++<span class="br0">)</span> <span class="co1">// for each vector</span>
     vector_sum<span class="br0">(</span>result<span class="br0">[</span>el<span class="br0">]</span>, source0<span class="br0">[</span>el<span class="br0">]</span>, source1<span class="br0">[</span>el<span class="br0">]</span><span class="br0">)</span>;
</pre></div>
<p>This is actually oversimplified. It assumes the instruction <code>vector_sum</code> works. Although this is what happens with <a href="/wiki/Intrinsic_function" title="Intrinsic function">instruction intrinsics</a>, much information is actually not taken into account here such as the number of vector components and their data format. This is done for clarity.</p>
<p>You can see however, this method reduces the number of decoded instructions from <i>numElements * componentsPerElement</i> to <i>numElements</i>. The number of jump instructions is also decreased. Another gain lies in the parallel execution of the four mathematical operations, giving a great speed up.</p>
<p>What happened however is that the packed SIMD register holds a certain amount of data so it's not possible to get more parallelism. The speed up is somewhat limited by the assumption we made of performing four parallel operations (please note this is common for both <a href="/wiki/AltiVec" title="AltiVec">AltiVec</a> and <a href="/wiki/Streaming_SIMD_Extensions" title="Streaming SIMD Extensions">SSE</a>).</p>
<p><a name="Parallel_Stream_paradigm_.28SIMD.2FMIMD.29" id="Parallel_Stream_paradigm_.28SIMD.2FMIMD.29"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=5" title="Edit section: Parallel Stream paradigm (SIMD/MIMD)">edit</a>]</span> <span class="mw-headline">Parallel Stream paradigm (SIMD/MIMD)</span></h3>
<div dir="ltr" style="text-align: left;">
<pre class="source-c">
 <span class="co1">// This is a fictional language for demonstration purposes.</span>
 streamElements <span class="nu0">100</span>
 streamElementFormat <span class="nu0">4</span> numbers
 elementKernel <span class="st0">"@arg0+@arg1"</span>
 result = kernel<span class="br0">(</span>source0, source1<span class="br0">)</span>
</pre></div>
<p>As you can see, the idea is to define the whole set of data instead of each single block. Describing the set of data is assumed to be in the first two rows. After that, the result is inferred from the sources and kernel. For simplicity, there's a 1:1 mapping between input and output data but this does not need to be. Applied kernels can also be much more complex.</p>
<p>An implementation of this paradigm can "unroll" a loop internally. This allows throughput to scale with chip complexity, easily utilizing hundreds of ALUs.<span class="reference plainlinksneverexpand" id="ref_scale"><sup><a href="http://en.wikipedia.org/wiki/Stream_processing#endnote_scale" class="external autonumber" title="http://en.wikipedia.org/wiki/Stream_processing#endnote_scale" rel="nofollow">[1]</a></sup></span> The elimination of complex data patterns makes much of this extra power available.</p>
<p>While stream processing is a branch of SIMD/MIMD processing, they must not be confused, although SIMD implementations can often work in a "streaming" manner, their performance is not comparable: the model envisions a much different usage pattern which allows far greater performance by itself. It has been noted<span class="reference plainlinksneverexpand" id="ref_GPPasStream"><sup><a href="http://en.wikipedia.org/wiki/Stream_processing#endnote_GPPasStream" class="external autonumber" title="http://en.wikipedia.org/wiki/Stream_processing#endnote_GPPasStream" rel="nofollow">[2]</a></sup></span> that when applied on generic processors such as standard CPU, only a 1.5x speedup can be reached. By contrast, ad-hoc stream processors easily reach over 10x performance, mainly attributed to the more efficient memory access and higher levels of parallel processing.</p>
<p>Although there are various degrees of flexibility allowed by the model, stream processors usually impose some limitations on the kernel or stream size. For example, consumer hardware often lacks the ability to perform high-precision math, lacks complex indirection chains or presents limits on the number of instructions which can be executed.</p>
<p><a name="Stream_processing_considerations" id="Stream_processing_considerations"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=6" title="Edit section: Stream processing considerations">edit</a>]</span> <span class="mw-headline">Stream processing considerations</span></h2>
<p>Available documentation on Stream processing is very scarce as of this writing (<span class="mw-formatted-date" title="2005-09-12"><span class="mw-formatted-date" title="09-12"><a href="/wiki/September_12" title="September 12">September 12</a></span>, <a href="/wiki/2005" title="2005">2005</a></span>). Only a few specialized institutions seem to have understood the implied power of the model. <a href="/wiki/Stanford_University" title="Stanford University">Stanford University</a> has been historically involved in a variety of projects on this, beginning from the <a href="http://graphics.stanford.edu/projects/shading/" class="external text" title="http://graphics.stanford.edu/projects/shading/" rel="nofollow">Stanford Shading language</a> and deploying a flexible, stand-alone stream processor called <a href="http://cva.stanford.edu/projects/imagine/" class="external text" title="http://cva.stanford.edu/projects/imagine/" rel="nofollow">Imagine</a>. Both those projects revealed the paradigm has a great potential so a much larger scale project has been started. With the name of <a href="http://merrimac.stanford.edu/" class="external text" title="http://merrimac.stanford.edu/" rel="nofollow">Merrimac</a>, a Stream-based supercomputer is now being researched. <a href="/wiki/AT%26T" title="AT&amp;T">AT&amp;T</a> also recognized the wide adoption of stream-enhanced processors as <a href="/wiki/Graphics_processing_unit" title="Graphics processing unit">GPUs</a> rapidly evolved in both speed and functionality.<span class="reference plainlinksneverexpand" id="ref_GPUasSTREAM"><sup><a href="http://en.wikipedia.org/wiki/Stream_processing#endnote_GPUasSTREAM" class="external autonumber" title="http://en.wikipedia.org/wiki/Stream_processing#endnote_GPUasSTREAM" rel="nofollow">[3]</a></sup></span></p>
<p><a name="Data_dependencies_and_parallelism" id="Data_dependencies_and_parallelism"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=7" title="Edit section: Data dependencies and parallelism">edit</a>]</span> <span class="mw-headline">Data dependencies and parallelism</span></h3>
<p>A great advantage of the stream programming model lies in the <i>kernel</i> defining <u>independent</u> and <u>local</u> data usage.</p>
<p>Kernel operations define the basic data unit, both as input and output. This allows the hardware to better allocate resources and schedule global I/O. Although usually not exposed in the programming model, the I/O operations seems to be much more advanced on stream processors (at least, on GPUs). I/O operations are also usually pipelined by themselves while chip structure can help hide latencies. Definition of the data unit is usually explicit in the kernel, which is expected to have well-defined inputs (possibly using structures, which is encouraged) and outputs. In some environments, output values are fixed (in GPUs for example, there is a fixed set of output attributes, unless this is relaxed). Having each computing block clearly independent and defined allows to schedule bulk read or write operations, greatly increasing cache and memory bus efficiency.</p>
<p>Data locality is also explicit in the kernel. This concept is usually referred to as <i>kernel locality</i>, identifying all the values which are short-lived to a single kernel <i>invocation</i>. All the temporaries are simply assumed to be local to each kernel invocation so, hardware or software can easily allocate them on fast registers. This is strictly related to degree of parallelism that can be exploited.</p>
<table class="metadata plainlinks ambox ambox-style" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Ambox_style.png" class="image" title="Ambox style.png"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/d/d6/Ambox_style.png" width="40" height="40" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article <b>may be <a href="/wiki/Wikipedia:Vagueness" title="Wikipedia:Vagueness">confusing or unclear</a> to readers</b>. Please help <a href="/wiki/Wikipedia:Manual_of_Style#Unnecessary_vagueness" title="Wikipedia:Manual of Style">clarify the article</a>; suggestions may be found on the <a href="/wiki/Talk:Stream_processing" title="Talk:Stream processing">talk page</a>. <small><i>(December 2006)</i></small></td>
</tr>
</table>
<p>Inside each kernel, producer-consumer relationships can be individuated by usual means while, when kernels are chained one after the another, this relationship is given by the model. This allows easier scheduling decisions because it's clear that if kernel <i>B</i> requires output from kernel <i>A</i>, it's obvious that <i>A</i> must be completed before <i>B</i> can be run (at least on the data unit being used). The Imagine chip's on-board stream controller module manages kernel loads and execution in hardware at runtime keeping a scoreboard of kernel dependencies (as told by the compiler) and can allow out-of-order execution to minimize stalls <i>producer-consumer locality</i>. This is another major new paradigm for high performance processing. The <a href="/wiki/Cell_processor" title="Cell processor" class="mw-redirect">Cell processor</a> allows this by routing data between various SPEs for example. In comparison, since the Imagine is a pure SIMD machine, inter-cluster communication and kernel execution is always explicit with much lower silicon overhead than a MIMD machine, such as Cell. Imagine uses 8 clusters (a.k.a lanes) of ALUs (similar to Cell's SPEs), but the clusters run in data-parallel mode executing a single kernel at a time. Task switching is done using conventional time-multiplexing. There is only one instruction decode for instance. The tradeoff here is that for kernels that can exploit lower levels of data-parallelism, the efficiency drops as not all clusters will do useful work. For a vast majority of DSP processing though this trade off pays off very well.</p>
<p>Recently, CPU vendors have been pushing for multi-core and multi-threading. While this trend is going to be useful for the average user, there's no chance standard CPUs can reach a stream processor's performance.</p>
<p>The parallelism between two kernel instances is similar to a <a href="/wiki/Thread_(computer_science)" title="Thread (computer science)">thread</a> level parallelism. Each kernel instance gets data parallelism. Inside each kernel, it is still possible to use instruction level parallelism. Task parallelism (such as overlapped I/O) can still happen. It's easy to have thousands of kernel instances but it's simply impossible to have the same amounts of threads. This is the power of the stream..</p>
<p><a name="Programming_model_notes" id="Programming_model_notes"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=8" title="Edit section: Programming model notes">edit</a>]</span> <span class="mw-headline">Programming model notes</span></h3>
<p>The most immediate challenge in the realm of parallel processing does not lie as much in the type of hardware architecture used, but in how easy it will be to program the system in question in a real-world environment with acceptable performance. Machines like Imagine use a straightforward single-threaded model with automated dependencies, memory allocation and DMA scheduling. This in itself is a result of the research at MIT and Stanford in finding an optimal <i>layering of tasks</i> between programmer, tools and hardware. Programmers beat tools in mapping algorithms to parallel hardware, and tools beat programmers in figuring out smartest memory allocation schemes, etc. Of particular concern are MIMD designs such as Cell, for which the programmer needs to deal with application partitioning across multiple cores and deal with process synchronization and load balancing. Efficient multi-core programming tools are severely lacking today.</p>
<p>One of the drawbacks of SIMD programming was the issue of <i>Array-of-Structures (AoS)</i> and <i>Structure-of-Arrays (SoA)</i>. Programmers often wanted to build data structures with a 'real' meaning, for example:</p>
<div dir="ltr" style="text-align: left;">
<pre class="source-c">
 <span class="co1">// A particle in a three dimensional space.</span>
 <span class="kw4">struct</span> particle_t
     <span class="kw4">float</span> x, y, z;          <span class="co1">// not even an array!</span>
     <span class="kw4">unsigned</span> byte color<span class="br0">[</span><span class="nu0">3</span><span class="br0">]</span>; <span class="co1">// 8 bit per channel, say we care about RGB only</span>
     <span class="kw4">float</span> size;
     <span class="co1">// ... and many other attributes may follow...</span>
</pre></div>
<p>What happened is that those structures were then assembled in <a href="/wiki/Array" title="Array">arrays</a> to keep things nicely organized. This is <b>AoS</b>. When the structure is laid out in memory, the compiler will produce interleaved data, in the sense that all the structures will be contiguous but there will be a constant offset between, say, the "size" attribute of a structure instance and the same element of the following instance. The offset depends on the structure definition (and possibly other things not considered here such as compiler's policies). There are also other problems. For example, the three position variables cannot be SIMD-ized that way, because it's not sure they will be allocated in continuous memory space. To make sure SIMD operations can work on them, they shall be grouped in a 'packed memory location' or at least in an array. Another problem lies in both "color" and "xyz" to be defined in three-component vector quantities. SIMD processors usually have support for 4-component operations only (with some exceptions however).</p>
<p>These kinds of problems and limitations made SIMD acceleration on standard CPUs quite nasty. The proposed solution, <i>SoA</i> follows as:</p>
<div dir="ltr" style="text-align: left;">
<pre class="source-c">
 <span class="kw4">struct</span> particle_t
     <span class="kw4">float</span> *x, *y, *z;
     <span class="kw4">unsigned</span> byte *colorRed, *colorBlue, *colorGreen;
     <span class="kw4">float</span> *size;
</pre></div>
<p>For readers not experienced with <a href="/wiki/C_(programming_language)" title="C (programming language)">C</a>, the '*' before each identifier means a pointer. In this case, they will be used to point to the first element of an array, which is to be allocated later. For <a href="/wiki/Java_(programming_language)" title="Java (programming language)">Java</a> programmers, this is roughly equivalent to "[]". The drawback here is that the various attributes could be spread in memory. To make sure this does not cause cache misses, we'll have to update all the various "reds", then all the "greens" and "blues". Although this is not so bad after all, it's simply overkill when compared to what most stream processors offer.</p>
<p>For stream processors, the usage of structures is encouraged. From an application point of view, all the attributes can be defined with some flexibility. Taking GPUs as reference, there is a set of attributes (at least 16) available. For each attribute, the application can state the number of components and the format of the components (but only primitive data types are supported for now). The various attributes are then attached to a memory block, possibly defining a <i>stride</i> between 'consecutive' elements of the same attributes, effectively allowing interleaved data. When the GPU begins the stream processing, it will <i>gather</i> all the various attributes in a single set of parameters (usually this looks like a structure or a "magic global variable"), performs the operations and <i>scatters</i> the results to some memory area for later processing (or retrieving).</p>
<p>Summing up, there's more flexibility on the application's side yet everything looks very organized on the stream processor's side.</p>
<p><a name="Generic_processor_architecture" id="Generic_processor_architecture"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=9" title="Edit section: Generic processor architecture">edit</a>]</span> <span class="mw-headline">Generic processor architecture</span></h3>
<p>Historically, CPUs began implementing various tiers of memory access optimizations because of the ever increasing performance when compared to relatively slow growing external memory bandwidth. As this gap widened, big amounts of die area were dedicated to hiding memory latencies. Since fetching information and opcodes to those few ALUs is expensive, very little die area is dedicated to actual mathematical machinery (as a rough estimation, consider it to be less than 10%).</p>
<p>A similar architecture exists on stream processors but thanks to the new programming model, the amount of transistors dedicated to management is actually very little.</p>
<p>Beginning from a whole system point of view, stream processors usually exist in a controlled environment. GPUs do exist on an add-in board (this seems to also apply to <a href="http://cva.stanford.edu/projects/imagine/" class="external text" title="http://cva.stanford.edu/projects/imagine/" rel="nofollow">Imagine</a>). CPUs do the dirty job of managing system resources, running applications and such.</p>
<p>The stream processor is usually equipped with a fast, efficient, proprietary memory bus (crossbar switches are now common, multi-buses have been employed in the past). The exact amount of memory lanes is dependent on the market range. As this is written, there are still 64-bit wide interconnections around (entry-level). Most mid-range models use a fast 128-bit crossbar switch matrix (4 or 2 segments), while high-end models deploy huge amounts of memory (actually up to 512MB) with a slightly slower crossbar that is 256 bits wide. By contrast, standard processors from <a href="/wiki/Intel_Pentium" title="Intel Pentium" class="mw-redirect">Intel Pentium</a> to some <a href="/wiki/Athlon_64" title="Athlon 64">Athlon 64</a> have only a single 64-bit wide data bus.</p>
<p>Memory access patterns are much more predictable. While arrays do exist, their dimension is fixed at kernel invocation. The thing which most closely matches a multiple pointer indirection is an <i>indirection chain</i>, which is however guaranteed to finally read or write from a specific memory area (inside a stream).</p>
<p>Because of the SIMD nature of the stream processor's execution units (ALUs clusters), read/write operations are expected to happen in bulk, so memories are optimized for high bandwidth rather than low latency (this is a difference from <a href="/wiki/Rambus" title="Rambus">Rambus</a> and <a href="/wiki/DDR_SDRAM" title="DDR SDRAM">DDR SDRAM</a>, for example). This also allows for efficient memory bus negotiations.</p>
<p>Most (90%) of a stream processor's work is done on-chip, requiring only 1% of the global data to be stored to memory. This is where knowing the kernel temporaries and dependencies pays.</p>
<p>Internally, a stream processor features some clever communication and management circuits but what's interesting is the <i>Stream Register File</i> (SRF). This is conceptually a large cache in which stream data is stored to be transferred to external memory in bulks. As a cache-like software-controlled structure to the various <a href="/wiki/Arithmetic_logic_unit" title="Arithmetic logic unit">ALUs</a>, the SRF is shared between all the various ALU clusters. The key concept and innovation here done with Stanford's Imagine chip is that the compiler is able to automate and allocate memory in an optimal way, fully transparent to the programmer. The dependencies between kernel functions and data is known through the programming model which enables the compiler to perform flow analysis and optimally pack the SRFs. Commonly, this cache and DMA management can take up the majority of a project's schedule, something the stream processor (or at least Imagine) totally automates. Tests done at Stanford showed that the compiler did an as well or better job at scheduling memory than if you hand tuned the thing with much effort.</p>
<p>There is proof, there can be only a lot of clusters because inter-cluster communication is assumed to be rare. Internally however, each cluster can efficiently exploit a much lower amount of ALUs because inter-cluster communication is common and thus needs to be highly efficient.</p>
<p>To keep those ALUs fetched with data, each ALU is equipped with Local Register Files (LRFs), which are basically its usable registers.</p>
<p>This three-tiered data access pattern, makes it easy to keep temporary data away from slow memories, thus making the silicon implementation highly efficient and power-saving.</p>
<p><a name="Hardware-in-the-loop_issues" id="Hardware-in-the-loop_issues"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=10" title="Edit section: Hardware-in-the-loop issues">edit</a>]</span> <span class="mw-headline">Hardware-in-the-loop issues</span></h3>
<table class="metadata plainlinks ambox ambox-style" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Ambox_style.png" class="image" title="Ambox style.png"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/d/d6/Ambox_style.png" width="40" height="40" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article <b>may be <a href="/wiki/Wikipedia:Vagueness" title="Wikipedia:Vagueness">confusing or unclear</a> to readers</b>. Please help <a href="/wiki/Wikipedia:Manual_of_Style#Unnecessary_vagueness" title="Wikipedia:Manual of Style">clarify the article</a>; suggestions may be found on the <a href="/wiki/Talk:Stream_processing" title="Talk:Stream processing">talk page</a>. <small><i>(January 2008)</i></small></td>
</tr>
</table>
<p>Although an order of magnitude speedup can easily be expected (even from mainstream GPUs when computing in a streaming manner), not all applications benefit from this. Communication latencies are actually the biggest problem. Although <a href="/wiki/PCI_Express" title="PCI Express">PCI Express</a> improved this with full-duplex communications, getting a GPU (and possibly a generic stream processor) to work will possibly take long amounts of time. This means it's usually counter-productive to use them for small datasets. The stream architecture also incurs penalties for small streams, a behaviour which is officially identified as <i>short stream effect</i>. This basically happens because changing the kernel is a rather expensive operation.</p>
<p><a href="/wiki/Instruction_pipeline" title="Instruction pipeline">Pipelining</a> is a very radicated practice on stream processors, with GPUs featuring pipelines exceeding 200 stages. The cost for switching settings is dependent on the setting being modified but it's now considered to always be expensive. Although efforts are being spent for lowering the cost of switching, it's predictable this isn't going to happen any time soon. To avoid those problems at various levels of the pipeline, many techniques have been deployed such as "Ã¼ber shaders" and "texture atlases". Those techniques are game-oriented because of the nature of GPUs, but the concepts are interesting for generic stream processing as well.</p>
<p><a name="Interesting_Stream_Processors" id="Interesting_Stream_Processors"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=11" title="Edit section: Interesting Stream Processors">edit</a>]</span> <span class="mw-headline">Interesting Stream Processors</span></h2>
<ul>
<li><a href="http://cva.stanford.edu/projects/imagine/" class="external text" title="http://cva.stanford.edu/projects/imagine/" rel="nofollow">Imagine</a>, headed by Professor <a href="/wiki/William_Dally" title="William Dally" class="mw-redirect">William Dally</a> of <a href="/wiki/Stanford_University" title="Stanford University">Stanford University</a>, is a flexible architecture intended to be both fast and energy efficient. The project, originally conceived in 1996, included architecture, software tools, a VLSI implementation and a development board, was funded by <a href="/wiki/DARPA" title="DARPA">DARPA</a>, <a href="/wiki/Intel" title="Intel" class="mw-redirect">Intel</a> and <a href="/wiki/Texas_Instruments" title="Texas Instruments">Texas Instruments</a>.</li>
<li>Another <a href="/wiki/Stanford" title="Stanford" class="mw-redirect">Stanford</a> project called <a href="http://merrimac.stanford.edu/" class="external text" title="http://merrimac.stanford.edu/" rel="nofollow">Merrimac</a> is aimed at developing a stream-based supercomputer. Merrimac intends to use a stream architecture and advanced interconnection networks to provide more performance per unit cost than cluster-based scientific computers built from the same technology.</li>
<li>The <b>Storm-1</b> Family from <a href="/wiki/Stream_Processors,_Inc" title="Stream Processors, Inc">Stream Processors, Inc</a>, a commercial spinoff of Stanford's <b>Imagine</b> project, was announced during a feature presentation at <a href="/wiki/ISSCC" title="ISSCC" class="mw-redirect">ISSCC</a> 2007. The family contains four members ranging from 30 GOPS to 220 16-bit GOPS (billions of operations per second), all fabricated at <a href="/wiki/TSMC" title="TSMC">TSMC</a> in a 130 nanometer process. The devices target the high end of the <a href="/wiki/Digital_signal_processor" title="Digital signal processor">DSP</a> market including <a href="/wiki/Video_conferencing" title="Video conferencing" class="mw-redirect">video conferencing</a>, <a href="/wiki/Multifunction_printer" title="Multifunction printer">multifunction printers</a> and digital <a href="/wiki/Video_surveillance" title="Video surveillance" class="mw-redirect">video surveillance</a> equipment.</li>
<li><a href="/wiki/GPU" title="GPU" class="mw-redirect">GPUs</a> are widespread, consumer-grade stream processors<span class="reference plainlinksneverexpand" id="ref_GPUasSTREAM"><sup><a href="http://en.wikipedia.org/wiki/Stream_processing#endnote_GPUasSTREAM" class="external autonumber" title="http://en.wikipedia.org/wiki/Stream_processing#endnote_GPUasSTREAM" rel="nofollow">[4]</a></sup></span> designed mainly by <a href="/wiki/ATI" title="ATI" class="mw-redirect">ATI</a> (now a division of <a href="/wiki/AMD" title="AMD" class="mw-redirect">AMD</a>) and <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a>. Various generations to be noted from a stream processing point of view:
<ul>
<li>Pre-NV2x: no explicit support for stream processing. Kernel operations were hidden in the <a href="/wiki/API" title="API" class="mw-redirect">API</a> and provided too little flexibility for general use.</li>
<li>NV2x: kernel stream operations became explicitly under the programmer's control but only for vertex processing (fragments were still using old paradigms). No branching support severely hampered flexibility but some types of algorithms could be run (notably, low-precision fluid simulation).</li>
<li>NV4x: flexible branching support although some limitations still exist on the number of operations to be executed and strict recursion depth, as well as array manipulation.</li>
<li>G8x: This generation is the state of the art.</li>
</ul>
</li>
<li>The <a href="/wiki/Cell_processor" title="Cell processor" class="mw-redirect">Cell processor</a> from <b>STI</b>, an alliance of <a href="/wiki/Sony_Computer_Entertainment" title="Sony Computer Entertainment">Sony Computer Entertainment</a>, <a href="/wiki/Toshiba_Corporation" title="Toshiba Corporation" class="mw-redirect">Toshiba Corporation</a>, and <a href="/wiki/IBM" title="IBM">IBM</a>, is a hardware architecture that can function like a stream processor with appropriate software support. It consists of a controlling processor, the PPE (Power Processing Element, an IBM <a href="/wiki/PowerPC" title="PowerPC">PowerPC</a>) and a set of SIMD coprocessors, called SPEs (Synergistic Processing Elements), each with independent program counters and instruction memory, in effect a <a href="/wiki/MIMD" title="MIMD">MIMD</a> machine. In the native programming model all DMA and program scheduling is left up to the programmer. The hardware provides a fast ring bus among the processors for local communication. Because the local memory for instructions and data is limited the only programs that can exploit this architecture effectively either require a tiny memory footprint or adhere to a stream programming model. With a suitable algorithm the performance of the Cell can rival that of pure stream processors, however this nearly always requires a complete redesign of algorithms and software.</li>
</ul>
<p><a name="Stream_Programming_Languages" id="Stream_Programming_Languages"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=12" title="Edit section: Stream Programming Languages">edit</a>]</span> <span class="mw-headline">Stream Programming Languages</span></h2>
<p>Most programming languages for stream processors start with C or C++ and add extensions which provide specific instructions to allow application developers to tag kernels and/or streams. This also applies to most <a href="/wiki/Shading_language" title="Shading language">shading languages</a>, which can be considered some kind of stream programming languages to a certain degree.</p>
<p>Non-commercial examples of stream programming languages include:</p>
<ul>
<li><a href="http://www.hitech-projects.com/euprojects/ACOTES/" class="external text" title="http://www.hitech-projects.com/euprojects/ACOTES/" rel="nofollow">ACOTES</a> Programming Model: language from <a href="/wiki/Polytechnic_University_of_Catalonia" title="Polytechnic University of Catalonia">Polytechnic University of Catalonia</a> based on <a href="/wiki/OpenMP" title="OpenMP">OpenMP</a></li>
<li><a href="http://graphics.stanford.edu/projects/brookgpu/lang.html" class="external text" title="http://graphics.stanford.edu/projects/brookgpu/lang.html" rel="nofollow">Brook</a> language from <a href="/wiki/Stanford" title="Stanford" class="mw-redirect">Stanford</a></li>
<li><a href="/wiki/OpenCL" title="OpenCL">OpenCL</a>, an open standard</li>
<li><a href="http://www.libsh.org/" class="external text" title="http://www.libsh.org/" rel="nofollow">Sh</a> library from the <a href="/wiki/University_of_Waterloo" title="University of Waterloo">University of Waterloo</a></li>
<li><a href="http://shallows.sourceforge.net/" class="external text" title="http://shallows.sourceforge.net/" rel="nofollow">Shallows</a>, an open source project</li>
<li><a href="http://www.cag.csail.mit.edu/streamit/" class="external text" title="http://www.cag.csail.mit.edu/streamit/" rel="nofollow">StreamIt</a> from <a href="/wiki/MIT" title="MIT" class="mw-redirect">MIT</a></li>
</ul>
<p>Commercial implementations are either general purpose or tied to specific hardware by a vendor. Examples of general purpose languages include:</p>
<ul>
<li><a href="/wiki/AccelerEyes" title="AccelerEyes">AccelerEyes</a>, a commercialization of a GPU engine for MATLAB</li>
<li><a href="http://www.emergent.net/Products/Gamebryo/Technical-Details/Floodgate/" class="external text" title="http://www.emergent.net/Products/Gamebryo/Technical-Details/Floodgate/" rel="nofollow">Floodgate</a>, a stream processor provided with the <a href="/wiki/Gamebryo" title="Gamebryo">Gamebryo</a> game engine for PlayStation3, Xbox360, Wii, and PC</li>
<li><a href="http://www.caps-entreprise.com/hmpp.html" class="external text" title="http://www.caps-entreprise.com/hmpp.html" rel="nofollow">HMPP</a>, a "directive" vision of Many-Core programming</li>
<li>PeakStream,<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup> a spinout of the <b><a href="/wiki/BrookGPU" title="BrookGPU">Brook</a></b> project (acquired by <a href="/wiki/List_of_Google_acquisitions" title="List of Google acquisitions" class="mw-redirect">Google</a> in June 2007)</li>
<li><a href="/wiki/RapidMind" title="RapidMind">RapidMind</a>, a commercialization of Sh</li>
<li>TStreams,<sup id="cite_ref-1" class="reference"><a href="#cite_note-1" title=""><span>[</span>2<span>]</span></a></sup><sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup> Hewlett-Packard Cambridge Research Lab</li>
</ul>
<p>Vendor-specific languages include:</p>
<ul>
<li>Brook+ (AMD hardware optimized implementation of <a href="/wiki/BrookGPU" title="BrookGPU">Brook</a>) from <a href="/wiki/AMD" title="AMD" class="mw-redirect">AMD</a>/<a href="/wiki/ATI_Technologies" title="ATI Technologies">ATI</a></li>
<li><a href="/wiki/CUDA" title="CUDA">CUDA</a> (Compute Unified Device Architecture) from <a href="/wiki/Nvidia" title="Nvidia">Nvidia</a></li>
<li><a href="/wiki/Intel_Ct" title="Intel Ct">Intel Ct</a> - C for Throughput Computing</li>
<li>StreamC from <a href="/wiki/Stream_Processors,_Inc" title="Stream Processors, Inc">Stream Processors, Inc</a>, a commercialization of the Imagine work at Stanford</li>
</ul>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=13" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="/wiki/GPGPU" title="GPGPU">GPGPU</a></li>
<li><a href="/wiki/MIMD" title="MIMD">MIMD</a></li>
<li><a href="/wiki/Parallel_computing" title="Parallel computing">Parallel computing</a></li>
<li><a href="/wiki/Molecular_modeling_on_GPU" title="Molecular modeling on GPU">Molecular modeling on GPU</a></li>
<li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li>
<li><a href="/wiki/Vector_processor" title="Vector processor">Vector processor</a></li>
<li><a href="/wiki/Dataflow" title="Dataflow">Dataflow</a></li>
</ul>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=14" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> <a href="http://arstechnica.com/news.ars/post/20060918-7763.html" class="external text" title="http://arstechnica.com/news.ars/post/20060918-7763.html" rel="nofollow">PeakStream unveils multicore and CPU/GPU programming solution</a></li>
<li id="cite_note-1"><b><a href="#cite_ref-1" title="">^</a></b> <a href="http://www.hpl.hp.com/techreports/2004/HPL-2004-78R1.html" class="external text" title="http://www.hpl.hp.com/techreports/2004/HPL-2004-78R1.html" rel="nofollow">TStreams: A Model of Parallel Computation</a></li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> <a href="http://www.hpl.hp.com/techreports/2004/HPL-2004-193.html" class="external text" title="http://www.hpl.hp.com/techreports/2004/HPL-2004-193.html" rel="nofollow">TStreams: How to Write a Parallel Program</a></li>
</ol>
</div>
<p><a name="Notes" id="Notes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=15" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline">Notes</span></h2>
<ol>
<li><cite id="endnote_scale" style="font-style: normal;"><a href="#ref_scale" title=""><b>^</b></a></cite>&#160; IEEE Journal of Solid-State Circuits:<a href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4443192" class="external text" title="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4443192" rel="nofollow">"A Programmable 512 GOPS Stream Processor for Signal, Image, and Video Processing"</a>, Stanford University and Stream Processors, Inc.</li>
<li><cite id="endnote_scale" style="font-style: normal;"><a href="#ref_scale" title=""><b>^</b></a></cite>&#160; Khailany, Dally, Rixner, Kapasi, Owens and Towles: <a href="http://cva.stanford.edu/publications/2003/khailany_im_scalability.pdf" class="external text" title="http://cva.stanford.edu/publications/2003/khailany_im_scalability.pdf" rel="nofollow">"Exploring VLSI Scalability of Stream Processors"</a>, Stanford and Rice University.</li>
<li><cite id="endnote_GPPasStream" style="font-style: normal;"><a href="#ref_GPPasStream" title=""><b>^</b></a></cite>&#160; Gummaraju and Rosenblum, <a href="http://www.cs.utexas.edu/users/skeckler/wild04/Paper14.pdf" class="external text" title="http://www.cs.utexas.edu/users/skeckler/wild04/Paper14.pdf" rel="nofollow">"Stream processing in General-Purpose Processors"</a>, Stanford University.</li>
<li><cite id="endnote_GPUasSTREAM" style="font-style: normal;"><a href="#ref_GPUasSTREAM" title=""><b>^</b></a></cite>&#160; Venkatasubramanian, <a href="http://www.research.att.com/~suresh/papers/mpds/mpds.pdf" class="external text" title="http://www.research.att.com/~suresh/papers/mpds/mpds.pdf" rel="nofollow">"The Graphics Card as a Stream Computer"</a>, <a href="/wiki/AT%26T_Labs" title="AT&amp;T Labs">AT&amp;T Labs</a> - research.</li>
<li><cite id="endnote_ProgStreamProc" style="font-style: normal;"><a href="#ref_ProgStreamProc" title=""><b>^</b></a></cite>&#160; Kapasi, Dally, Rixner, Khailany, Owens, Ahn and Mattson, <a href="http://cva.stanford.edu/publications/2003/ieeecomputer_stream.pdf" class="external text" title="http://cva.stanford.edu/publications/2003/ieeecomputer_stream.pdf" rel="nofollow">"Programmable Stream Processors"</a>, Universities of Stanford, Rice, California (Davis) and Reservoir Labs.</li>
</ol>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Stream_processing&amp;action=edit&amp;section=16" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://ati.amd.com/products/streamprocessor/index.html|" class="external text" title="http://ati.amd.com/products/streamprocessor/index.html|" rel="nofollow">Press Release</a> Launch information for AMD's dedicated R580 GPU-based Stream Processing unit for enterprise solutions.</li>
</ul>
<table class="navbox" cellspacing="0" style=";">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks collapsible autocollapse" style="width:100%;background:transparent;color:inherit;;">
<tr>
<th style=";" colspan="2" class="navbox-title">
<div style="float:left; width:6em;text-align:left;">
<div class="noprint plainlinksneverexpand navbar" style="background:none; padding:0; font-weight:normal;;;border:none;; font-size:xx-small;"><a href="/wiki/Template:Parallel_computing" title="Template:Parallel computing"><span title="View this template" style=";;border:none;">v</span></a>&#160;<span style="font-size:80%;">â¢</span>&#160;<a href="/wiki/Template_talk:Parallel_computing" title="Template talk:Parallel computing"><span title="Discussion about this template" style=";;border:none;">d</span></a>&#160;<span style="font-size:80%;">â¢</span>&#160;<a href="http://en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit" rel="nofollow"><span title="Edit this template" style=";;border:none;;">e</span></a></div>
</div>
<span style="font-size:110%;"><a href="/wiki/Parallel_computing" title="Parallel computing">Parallel computing</a> topics</span></th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">General</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/High-performance_computing" title="High-performance computing">High-performance computing</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Cluster_(computing)" title="Cluster (computing)">Cluster computing</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Distributed_computing" title="Distributed computing">Distributed computing</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Grid_computing" title="Grid computing">Grid computing</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Parallelism (levels)</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Bit-level_parallelism" title="Bit-level parallelism">Bit</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Instruction_level_parallelism" title="Instruction level parallelism">Instruction</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Data_parallelism" title="Data parallelism">Data</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Task_parallelism" title="Task parallelism">Task</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Threads</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Super-threading" title="Super-threading">Superthreading</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Hyper-threading" title="Hyper-threading">Hyperthreading</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Theory</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Amdahl%27s_law" title="Amdahl's law">Amdahl's law</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Gustafson%27s_law" title="Gustafson's law">Gustafson's law</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Cost_efficiency" title="Cost efficiency">Cost efficiency</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Karp-Flatt_metric" title="Karp-Flatt metric">Karp-Flatt metric</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Parallel_slowdown" title="Parallel slowdown">slowdown</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Speedup" title="Speedup">speedup</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Elements</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Process_(computing)" title="Process (computing)">Process</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Thread_(computer_science)" title="Thread (computer science)">Thread</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Fiber_(computer_science)" title="Fiber (computer science)">Fiber</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Parallel_Random_Access_Machine" title="Parallel Random Access Machine">PRAM</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Coordination</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Multithreading_(computer_hardware)" title="Multithreading (computer hardware)">Multithreading</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Memory_coherence" title="Memory coherence">Memory coherency</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Cache_coherency" title="Cache coherency" class="mw-redirect">Cache coherency</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Barrier_(computer_science)" title="Barrier (computer science)">Barrier</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Synchronization_(computer_science)" title="Synchronization (computer science)">Synchronization</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Application_checkpointing" title="Application checkpointing">Application checkpointing</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Computer_programming" title="Computer programming">Programming</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Parallel_programming_model" title="Parallel programming model">Models</a> (<a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a>) <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Flynn%27s_taxonomy" title="Flynn's taxonomy">Flynn's taxonomy</a> <small>(<a href="/wiki/SISD" title="SISD">SISD</a>&#160;â¢ <a href="/wiki/SIMD" title="SIMD">SIMD</a>&#160;â¢ <a href="/wiki/MISD" title="MISD">MISD</a>&#160;â¢ <a href="/wiki/MIMD" title="MIMD">MIMD</a>)</small></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Computer_hardware" title="Computer hardware" class="mw-redirect">Hardware</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">Multiprocessing (<a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">Symmetric</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">Asymmetric</a>) <span style="font-weight:bold;">&#160;Â·</span> Memory (<a href="/wiki/Non-Uniform_Memory_Access" title="Non-Uniform Memory Access">NUMA</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Cache_only_memory_architecture" title="Cache only memory architecture">COMA</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Shared_memory" title="Shared memory">shared</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a>) <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Simultaneous_multithreading" title="Simultaneous multithreading">SMT</a><br />
<a href="/wiki/Massive_parallel_processing" title="Massive parallel processing">MPP</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Superscalar" title="Superscalar">Superscalar</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Vector_processor" title="Vector processor">Vector processor</a> <span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Supercomputer" title="Supercomputer">Supercomputer</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Beowulf_(computing)" title="Beowulf (computing)"><i>Beowulf</i></a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;"><a href="/wiki/Application_programming_interface" title="Application programming interface">APIs</a></td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em"><a href="/wiki/POSIX_Threads" title="POSIX Threads">POSIX Threads</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/OpenMP" title="OpenMP">OpenMP</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Message_Passing_Interface" title="Message Passing Interface">MPI</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Unified_Parallel_C" title="Unified Parallel C">UPC</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Intel_Threading_Building_Blocks" title="Intel Threading Building Blocks">Intel Threading Building Blocks</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Boost_C%2B%2B_Libraries#Multithreading_.E2.80.93_Boost.Thread" title="Boost C++ Libraries">Boost.Thread</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Global_Arrays" title="Global Arrays">Global Arrays</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Charm%2B%2B" title="Charm++">Charm++</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Cilk" title="Cilk">Cilk</a></div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<td class="navbox-group" style=";;">Problems</td>
<td style="text-align:left;border-left:2px solid #fdfdfd;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"><a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">Embarrassingly parallel</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Grand_Challenge_problem" title="Grand Challenge problem">Grand Challenge</a><span style="font-weight:bold;">&#160;Â·</span> <a href="/wiki/Software_lockout" title="Software lockout">Software lockout</a></div>
</td>
</tr>
</table>
</td>
</tr>
</table>


<!-- 
NewPP limit report
Preprocessor node count: 1389/1000000
Post-expand include size: 39043/2048000 bytes
Template argument size: 12614/2048000 bytes
Expensive parser function count: 1/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:2786727-0!1!0!default!!en!2 and timestamp 20090406180250 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Stream_processing">http://en.wikipedia.org/wiki/Stream_processing</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Computer_architecture" title="Category:Computer architecture">Computer architecture</a></span> | <span dir='ltr'><a href="/wiki/Category:Programming_paradigms" title="Category:Programming paradigms">Programming paradigms</a></span> | <span dir='ltr'><a href="/wiki/Category:Computational_models" title="Category:Computational models">Computational models</a></span> | <span dir='ltr'><a href="/wiki/Category:GPGPU" title="Category:GPGPU">GPGPU</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:All_articles_to_be_merged" title="Category:All articles to be merged">All articles to be merged</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_to_be_merged_since_October_2008" title="Category:Articles to be merged since October 2008">Articles to be merged since October 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_with_unsourced_statements_since_June_2008" title="Category:Articles with unsourced statements since June 2008">Articles with unsourced statements since June 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_December_2006" title="Category:Wikipedia articles needing clarification from December 2006">Wikipedia articles needing clarification from December 2006</a></span> | <span dir='ltr'><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_January_2008" title="Category:Wikipedia articles needing clarification from January 2008">Wikipedia articles needing clarification from January 2008</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Stream_processing" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Stream_processing" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Stream_processing&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Stream_processing&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Stream_processing" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content â the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Stream_processing" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Stream_processing" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Stream_processing&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Stream_processing&amp;oldid=272820101" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Stream_processing&amp;id=272820101">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-ar"><a href="http://ar.wikipedia.org/wiki/%D8%AA%D8%AD%D9%84%D9%8A%D9%84_%D9%85%D8%AA%D8%AF%D9%81%D9%82">Ø§ÙØ¹Ø±Ø¨ÙØ©</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Streamprozessor">Deutsch</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC%E3%83%A0%E3%83%BB%E3%83%97%E3%83%AD%E3%82%BB%E3%83%83%E3%82%B7%E3%83%B3%E3%82%B0">æ¥æ¬èª</a></li>
				<li class="interwiki-uk"><a href="http://uk.wikipedia.org/wiki/%D0%91%D0%B0%D0%B3%D0%B0%D1%82%D0%BE%D0%BF%D0%BE%D1%82%D0%BE%D0%BA%D0%BE%D0%B2%D0%B5_%D0%BE%D0%B1%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BD%D0%BD%D1%8F_%D0%B4%D0%B0%D0%BD%D0%B8%D1%85">Ð£ÐºÑÐ°ÑÐ½ÑÑÐºÐ°</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 23 February 2009, at 22:17 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv177 in 0.063 secs. --></body></html>
