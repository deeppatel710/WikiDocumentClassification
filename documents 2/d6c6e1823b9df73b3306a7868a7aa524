<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Symbol grounding,Anti-psychologism,Anti-realism,C. K. Ogden,Categorical Perception,Causal theory of reference,Chinese Room,Cognitivism,Communicative action,Computational theory of mind,Computationalism" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Symbol_grounding&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Symbol_grounding&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Symbol grounding - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Symbol_grounding";
		var wgTitle = "Symbol grounding";
		var wgAction = "view";
		var wgArticleId = "3446949";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 272414253;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Symbol_grounding skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Symbol grounding</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<table class="metadata plainlinks ambox ambox-style" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Ambox_style.png" class="image" title="Ambox style.png"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/d/d6/Ambox_style.png" width="40" height="40" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article's <b><a href="/wiki/Wikipedia:TONE" title="Wikipedia:TONE" class="mw-redirect">tone</a> or style may not be appropriate for Wikipedia</b>. Specific concerns may be found on the <a href="/wiki/Talk:Symbol_grounding" title="Talk:Symbol grounding">talk page</a>. See Wikipedia's <a href="/wiki/Wikipedia:Guide_to_writing_better_articles" title="Wikipedia:Guide to writing better articles" class="mw-redirect">guide to writing better articles</a> for suggestions. <small><i>(November 2008)</i></small></td>
</tr>
</table>
<table class="metadata plainlinks ambox ambox-content" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><a href="/wiki/File:Unbalanced_scales.svg" class="image" title="Unbalanced scales.svg"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/fe/Unbalanced_scales.svg/45px-Unbalanced_scales.svg.png" width="45" height="40" border="0" /></a></div>
</td>
<td class="mbox-text" style="">This article <b>may be inaccurate or <a href="/wiki/Wikipedia:Neutral_point_of_view#Undue_weight" title="Wikipedia:Neutral point of view">unbalanced</a> in favor of certain viewpoints</b>. Please <a href="http://en.wikipedia.org/w/index.php?title=Symbol_grounding&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Symbol_grounding&amp;action=edit" rel="nofollow">improve the article</a> by adding information on neglected viewpoints, or discuss the issue on the <a href="/wiki/Talk:Symbol_grounding" title="Talk:Symbol grounding">talk page</a>.</td>
</tr>
</table>
<p>The <b>Symbol Grounding Problem</b> is related to the problem of how <a href="/wiki/Word" title="Word">words</a> (<a href="/wiki/Symbol" title="Symbol">symbols</a>) get their <a href="/wiki/Meaning" title="Meaning">meanings</a>, and hence to the problem of what meaning itself really is. The <a href="/w/index.php?title=Problem_of_meaning&amp;action=edit&amp;redlink=1" class="new" title="Problem of meaning (page does not exist)">problem of meaning</a> is in turn related to the <a href="/w/index.php?title=Problem_of_consciousness&amp;action=edit&amp;redlink=1" class="new" title="Problem of consciousness (page does not exist)">problem of consciousness</a>, or how it is that <a href="/wiki/Mental_state" title="Mental state">mental states</a> are meaningful. According to a widely held <a href="/w/index.php?title=Theory_of_cognition&amp;action=edit&amp;redlink=1" class="new" title="Theory of cognition (page does not exist)">theory of cognition</a>, "<a href="/wiki/Computationalism" title="Computationalism" class="mw-redirect">computationalism</a>," cognition (i.e., thinking) is just a form of computation. But computation in turn is just formal symbol manipulation: symbols are manipulated according to rules that are based on the symbols' shapes, not their meanings. How are those symbols (e.g., the words in our heads) connected to the things they refer to? It cannot be through the mediation of an external interpreter's head, because that would lead to an infinite regress, just as my looking up the meanings of words in a (unilingual) dictionary of a language that I do not understand would lead to an infinite regress. The symbols in an autonomous hybrid symbolic+sensorimotor system -- a Turing-scale robot consisting of both a symbol system and a sensorimotor system that reliably connects its internal symbols to the external objects they refer to, so it can interact with them Turing-indistinguishably from the way a person does -- would be grounded. But whether its symbols would have meaning rather than just grounding is something that even the robotic Turing Test -- hence cognitive science itself -- cannot determine, or explain.</p>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Words_and_Meanings"><span class="tocnumber">1</span> <span class="toctext">Words and Meanings</span></a></li>
<li class="toclevel-1"><a href="#Consciousness"><span class="tocnumber">2</span> <span class="toctext">Consciousness</span></a></li>
<li class="toclevel-1"><a href="#Symbol_Grounding_and_Computation"><span class="tocnumber">3</span> <span class="toctext">Symbol Grounding and Computation</span></a>
<ul>
<li class="toclevel-2"><a href="#Functionalism"><span class="tocnumber">3.1</span> <span class="toctext">Functionalism</span></a></li>
<li class="toclevel-2"><a href="#Searle.27s_Chinese_Room_Argument"><span class="tocnumber">3.2</span> <span class="toctext">Searle's Chinese Room Argument</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Formulation_of_Symbol_Grounding_Problem"><span class="tocnumber">4</span> <span class="toctext">Formulation of Symbol Grounding Problem</span></a></li>
<li class="toclevel-1"><a href="#Requirements_for_Symbol_Grounding"><span class="tocnumber">5</span> <span class="toctext">Requirements for Symbol Grounding</span></a>
<ul>
<li class="toclevel-2"><a href="#Capacity_to_Pick_Out_Referents"><span class="tocnumber">5.1</span> <span class="toctext">Capacity to Pick Out Referents</span></a></li>
<li class="toclevel-2"><a href="#Consciousness_2"><span class="tocnumber">5.2</span> <span class="toctext">Consciousness</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Symbol_Grounding_and_Brentano.27s_Notion_of_Intentionality"><span class="tocnumber">6</span> <span class="toctext">Symbol Grounding and Brentano's Notion of Intentionality</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">7</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#Footnotes"><span class="tocnumber">8</span> <span class="toctext">Footnotes</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Words_and_Meanings" id="Words_and_Meanings"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=1" title="Edit section: Words and Meanings">edit</a>]</span> <span class="mw-headline">Words and Meanings</span></h2>
<p>We know since <a href="/wiki/Gottlob_Frege" title="Gottlob Frege">Frege</a> that the thing that a word refers to (i.e., its referent) is not the same as its meaning (or "sense"). This is most clearly illustrated using the proper names of concrete individuals, but it is also true of names of kinds of things and of abstract properties: (1) "Tony Blair," (2) "the UK's former prime minister," and (3) "Cherie Blair's husband" all have the same referent, but not the same meaning. (It should be noted that although it draws in places upon Frege's view of semantics, this article is very anti-Fregean in stance. Frege was a fierce critic of psychological accounts that attempt to explain meaning in terms of mental states.)</p>
<p>Some have suggested that the meaning of a (referring) word is the rule or features that one must use in order to successfully pick out its referent. In that respect, (2) and (3) come closer to wearing their meanings on their sleeves, because they are explicitly stating a rule for picking out their referents: "Find whoever is the UK's former PM, or whoever is Cherie's current husband". But that does not settle the matter, because there's still the problem of the meaning of the components of that rule ("UK," "former," "current," "PM," "Cherie," "husband"), and how to pick <i>them</i> out.</p>
<p>Perhaps "Tony Blair" (or better still, just "Tony") does not have this recursive component problem, because it points straight to its referent, but how? If the meaning is the rule for picking out the referent, what is that rule, when we come down to non-decomposable components like proper names of individuals (or names of <i>kinds</i>, as in "an unmarried man" is a "bachelor")?</p>
<p>It is probably unreasonable to expect us to know the <a href="/wiki/Philosophical_Investigations#Rules" title="Philosophical Investigations">rule</a> for picking out the intended referents of our words,-- to know it explicitly, at least. Our brains do need to have the "know-how" to <i>execute</i> the rule, whatever it happens to be: they need to be able to actually pick out the intended referents of our words, such as "Tony Blair" or "bachelor." But <i>we</i> do not need to know consciously <i>how</i> our brains do that; we needn't know the rule. We can leave it to cognitive science and neuroscience to find out how our brains do it, and then explain the rule to us explicitly.</p>
<p>So if we take a word's meaning to be the means of picking out its referent, then meanings are in our brains. That is meaning in the <i>narrow</i> sense. If we use "meaning" in a <i>wider</i> sense, then we may want to say that meanings include both the referents themselves and the means of picking them out. So if a word (say, "Tony-Blair") is located inside an entity (e.g., me) that can use the word and pick out its referent, then the word's wide meaning consists of both the means that that entity uses to pick out its referent, and the referent itself: a wide causal nexus between (1) a head, (2) a word inside it, (3) an object outside it, and (4) whatever "processing" is required in order to successfully connect the inner word to the outer object.</p>
<p>But what if the "entity" in which a word is located is not a head but a piece of paper (or screen)? What is its meaning then? Surely all the (referring) words on this page, for example, have meanings, just as they have referents.</p>
<p><a name="Consciousness" id="Consciousness"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=2" title="Edit section: Consciousness">edit</a>]</span> <span class="mw-headline">Consciousness</span></h2>
<p>Here is where the problem of consciousness rears its head.<sup id="cite_ref-0" class="reference"><a href="#cite_note-0" title=""><span>[</span>1<span>]</span></a></sup> For there would be no connection at all between scratches on paper and any intended referents if there were no minds mediating those intentions, via their own internal means of picking out those intended referents.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1" title=""><span>[</span>2<span>]</span></a></sup></p>
<p>So the meaning of a word on a page is "ungrounded."<sup id="cite_ref-2" class="reference"><a href="#cite_note-2" title=""><span>[</span>3<span>]</span></a></sup> Nor would looking it up in a dictionary help: If I tried to look up the meaning of a word I did not understand in a (unilingual) dictionary of a language I did not already understand, I would just cycle endlessly from one meaningless definition to another. My search for meaning would be ungrounded. In contrast, the meaning of the words in my head -- the ones I <i>do</i> understand -- are "grounded" (by a means that cognitive neuroscience might eventually reveal to us). And that grounding of the meanings of the words in my head mediates between the words on any external page I read (and understand) and the external objects to which those words refer.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3" title=""><span>[</span>4<span>]</span></a></sup> <sup id="cite_ref-4" class="reference"><a href="#cite_note-4" title=""><span>[</span>5<span>]</span></a></sup></p>
<p><a name="Symbol_Grounding_and_Computation" id="Symbol_Grounding_and_Computation"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=3" title="Edit section: Symbol Grounding and Computation">edit</a>]</span> <span class="mw-headline">Symbol Grounding and Computation</span></h2>
<p>What about the meaning of a word inside a computer? Is it like the word on the page or like the word in my head? This is where the Symbol Grounding Problem comes in. Is a dynamic process transpiring in a computer more like the static paper page, or more like another dynamical system, the brain?</p>
<p><a name="Functionalism" id="Functionalism"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=4" title="Edit section: Functionalism">edit</a>]</span> <span class="mw-headline">Functionalism</span></h3>
<p>There is a school of thought according to which the computer is more like the brain -- or rather, the brain is more like the computer: According to this view (called " <a href="/wiki/Computational_theory_of_mind" title="Computational theory of mind">computationalism</a>", a variety of <a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">functionalism</a>), the future theory explaining how the brain picks out its referents (the theory that cognitive neuroscience may eventually arrive at) will be a purely computational one (Pylyshyn 1984). A computational theory is a theory at the software level. It is essentially a computer program: a set of rules for manipulating symbols. And software is "implementation-independent." That means that whatever it is that a program is doing, it will do the same thing no matter what hardware it is executed on. The physical details of the dynamical system implementing the computation are irrelevant to the computation itself, which is purely formal; any hardware that can run the computation will do, and all physical implementations of that particular computer program are equivalent, computationally.</p>
<p>A computer can execute any computation. Hence once computationalism finds the right computer program, the same one that our brain is running when there is meaning transpiring in our heads, meaning will be transpiring in that computer too, when it is executing that program.</p>
<p>How would we know that we have the right computer program? It would have to be able to pass the <a href="/wiki/Turing_Test" title="Turing Test" class="mw-redirect">Turing Test</a> (TT). That means it would have to be capable of corresponding with any human being as a pen-pal, for a lifetime, without ever being in any way distinguishable from a real human pen-pal.</p>
<p><a name="Searle.27s_Chinese_Room_Argument" id="Searle.27s_Chinese_Room_Argument"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=5" title="Edit section: Searle's Chinese Room Argument">edit</a>]</span> <span class="mw-headline">Searle's Chinese Room Argument</span></h3>
<p>It was in order to show that computationalism is incorrect that <a href="/wiki/John_Searle" title="John Searle">Searle</a> formulated his celebrated "<a href="/wiki/Chinese_Room" title="Chinese Room" class="mw-redirect">Chinese Room</a> Argument," in which he pointed out that if the Turing Test were conducted in Chinese, then he himself, Searle (who does not understand Chinese), could execute the very same program that the computer was executing without knowing what any of the words he was manipulating meant. So if there's no meaning going on inside Searle's head when he is implementing the program, then there's no meaning going on inside the computer when it is the one implementing the program either, computation being implementation-independent.</p>
<p>How does Searle know that there is no meaning going on in his head when he is executing the TT-passing program? Exactly the same way he knows whether there is or is not meaning going on inside his head under any other conditions: He <i>understands</i> the words of English, whereas the Chinese symbols that he is manipulating according to the program's rules mean nothing whatsoever to him (and there is no one else in in his head for them to mean anything to). The symbols that are coming in, being rulefully manipulated, and then being sent out by any implementation of the TT-passing computer program, whether Searle or a computer, are like the ungrounded words on a page, not the grounded words in a head.</p>
<p>Note that in pointing out that the Chinese words would be meaningless to him under those conditions, Searle has appealed to consciousness. Otherwise one could argue that there <i>would</i> be meaning going on in Searle's head under those conditions, but that Searle himself would simply not be conscious of it. That is called the <a href="http://plato.stanford.edu/entries/chinese-room/#4.1" class="external text" title="http://plato.stanford.edu/entries/chinese-room/#4.1" rel="nofollow">"Systems Reply"</a> to Searle's Chinese Room Argument, and Searle <a href="http://cogprints.org/4023/" class="external text" title="http://cogprints.org/4023/" rel="nofollow">rightly rejects</a> the Systems Reply as being merely a reiteration, in the face of negative evidence, of the very thesis (computationalism) that is on trial in his thought-experiment: "Are words in a running computation like the ungrounded words on a page, meaningless without the mediation of brains, or are they like the grounded words in brains?"</p>
<p>In this either/or question, the (still undefined) word "ungrounded" has implicitly relied on the difference between inert words on a page and consciously meaningful words in our heads. And Searle is reminding us that under these conditions (the Chinese TT), the words in his head would not be consciously meaningful, hence they would still be as ungrounded as the inert words on a page.</p>
<p>So if Searle is right, that (1) both the words on a page and those in any running computer program (including a TT-passing computer program) are meaningless in and of themselves, and hence that (2) whatever it is that the brain is doing to generate meaning, it can't be just implementation-independent computation, then what <i>is</i> the brain doing to generate meaning <a href="http://cogprints.org/4023/" class="external text" title="http://cogprints.org/4023/" rel="nofollow">(Harnad 2001a)</a>?</p>
<p><a name="Formulation_of_Symbol_Grounding_Problem" id="Formulation_of_Symbol_Grounding_Problem"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=6" title="Edit section: Formulation of Symbol Grounding Problem">edit</a>]</span> <span class="mw-headline">Formulation of Symbol Grounding Problem</span></h2>
<p>To answer this question we have to formulate the symbol grounding problem itself <a href="http://cogprints.org/3106/" class="external text" title="http://cogprints.org/3106/" rel="nofollow">(Harnad 1990)</a>:</p>
<p>First we have to define "symbol": A symbol is any object that is part of a <i>symbol system.</i> (The notion of single symbol in isolation is not a useful one.) Symbols are arbitrary in their shape. A symbol system is a set of symbols and syntactic rules for manipulating them on the basis of their shapes (not their meanings). The symbols are systematically interpretable as having meanings and referents, but their shape is arbitrary in relation to their meanings and the shape of their referents.</p>
<p>A numeral is as good an example as any: Numerals (e.g., "1," "2," "3,") are part of a symbol system (arithmetic) consisting of shape-based rules for combining the symbols into ruleful strings. "2" means what we mean by "two", but its shape in no way resembles, nor is it connected to, "two-ness." Yet the symbol system is systematically interpretable as making true statements about numbers (e.g. "1 + 1 = 2").</p>
<p>It is critical to understand the property that the symbol-manipulation rules are based on shape rather than meaning (the symbols are treated as primitive and undefined, insofar as the rules are concerned), yet the symbols and their ruleful combinations are all meaningfully interpretable. It should be evident in the case of formal arithmetic, that although the symbols make sense, that sense is in our heads and not in the symbol system. The numerals in a running desk calculator are as meaningless as the numerals on a page of hand-calculations. Only in our minds do they take on meaning (Harnad 1994).</p>
<p>This is not to deprecate the property of systematic interpretability: We select and design formal symbol systems (algorithms) precisely because we want to know and use their systematic properties; the systematic correspondence between scratches on paper and quantities in the universe is a remarkable and extremely powerful property. But it is not the same thing as meaning, which is a property of certain things going on in our heads.</p>
<p><a name="Requirements_for_Symbol_Grounding" id="Requirements_for_Symbol_Grounding"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=7" title="Edit section: Requirements for Symbol Grounding">edit</a>]</span> <span class="mw-headline">Requirements for Symbol Grounding</span></h2>
<p>Another symbol system is <a href="/wiki/Natural_language" title="Natural language">natural language</a> (Fodor 1975). On paper, or in a computer, language too is just a formal symbol system, manipulable by rules based on the arbitrary shapes of words. But in the brain, meaningless strings of squiggles become meaningful thoughts. Harnad has suggested viz. pointed at two properties that might be required to make this difference.</p>
<p><a name="Capacity_to_Pick_Out_Referents" id="Capacity_to_Pick_Out_Referents"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=8" title="Edit section: Capacity to Pick Out Referents">edit</a>]</span> <span class="mw-headline">Capacity to Pick Out Referents</span></h3>
<p>One property that the symbols on static paper or even in a dynamic computer lack that symbols in a brain possess is the capacity to pick out their referents. This is what we were discussing earlier, and it is what the hitherto undefined term "grounding" refers to. A symbol system alone, whether static or dynamic, cannot have this capacity (any more than a book can), because picking out referents is not just a computational (implementation-independent) property; it is a dynamical (implementation-dependent) property.</p>
<p>To be grounded, the symbol system would have to be augmented with nonsymbolic, sensorimotor capacities -- the capacity to interact autonomously with that world of objects, events, actions, properties and states that its symbols are systematically interpretable (by us) as referring to. It would have to be able to pick out the referents of its symbols, and its sensorimotor interactions with the world would have to fit coherently with the symbols' interpretations.</p>
<p>The symbols, in other words, need to be connected directly to (i.e., grounded in) their referents; the connection must not be dependent only on the connections made by the brains of external interpreters like us. Just the symbol system alone, without this capacity for direct grounding, is not a viable candidate for being whatever it is that is really going on in our brains when we think meaningful thoughts (Cangelosi &amp; Harnad 2001).</p>
<p><a name="Consciousness_2" id="Consciousness_2"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=9" title="Edit section: Consciousness">edit</a>]</span> <span class="mw-headline">Consciousness</span></h3>
<p>The necessity of groundedness, in other words, takes us from the level of the pen-pal <a href="/wiki/Turing_Test" title="Turing Test" class="mw-redirect">Turing Test</a>, which is purely symbolic (computational), to the robotic Turing Test, which is hybrid symbolic/sensorimotor (Harnad 2000, 2007). Meaning is grounded in the robotic capacity to detect, categorize, identify, and act upon the things that words and sentences refer to (see entry for <a href="/wiki/Categorical_Perception" title="Categorical Perception" class="mw-redirect">Categorical Perception</a>).</p>
<p>To categorize is to do the right thing with the right <i>kind</i> of thing. The categorizer must be able to detect the sensorimotor features of the members of the category that reliably distinguish them from the nonmembers. These feature-detectors must either be inborn or learned. The learning can be based on trial and error induction, guided by feedback from the consequences of correct and incorrect categorization; or, in our own linguistic species, the learning can also be based on verbal descriptions or definitions. The description or definition of a new category, however, can only convey the category and ground its name if the words in the definition are themselves already grounded category names Blondin-Mass√© et al. 2008). So ultimately grounding has to be sensorimotor, to avoid infinite regress (Harnad 2005).</p>
<p>But if groundedness is a necessary condition for meaning, is it a sufficient one? Not necessarily, for it is possible that even a robot that could pass the Turing Test, "living" amongst the rest of us indistinguishably for a lifetime, would fail to have in its head what Searle has in his: It could be a <a href="/wiki/Zombie" title="Zombie">Zombie</a>, with no one home, feeling feelings, meaning meanings (Harnad 1995).</p>
<p>Harnad thus points at consciousness as a second property. The problem of discovering the causal mechanism for successfully picking out the referent of a category name can in principle be solved by cognitive science. But the problem of explaining how consciousness can play an independent role in doing so is probably insoluble, except on pain of telekinetic dualism. Perhaps symbol grounding (i.e., robotic TT capacity) is enough to ensure that conscious meaning is present too, perhaps not. But in either case, there is no way we can hope to be any the wiser -- and that is Turing's methodological point (Harnad 2001b, 2003, 2006).</p>
<p><a name="Symbol_Grounding_and_Brentano.27s_Notion_of_Intentionality" id="Symbol_Grounding_and_Brentano.27s_Notion_of_Intentionality"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=10" title="Edit section: Symbol Grounding and Brentano's Notion of Intentionality">edit</a>]</span> <span class="mw-headline">Symbol Grounding and Brentano's Notion of Intentionality</span></h2>
<p>"Intentionality" has been called the "mark of the mental" because of some observations by the philosopher <a href="/wiki/Franz_Brentano" title="Franz Brentano">Brentano</a> to the effect that mental states always have an inherent, intended (mental) object or content toward which they are "directed": I see something, want something, believe something, desire something, understand something, mean something etc.; and that something is always something I have <i>in mind</i>. Having a mental object is part of having anything in mind. Hence it is the mark of the mental. There are no "free-floating" mental states that do not also have a mental object. Even hallucinations and imaginings have an object, and even feeling depressed feels like something. Nor is the object the "external" physical object, when there is one. I may see a real chair, but the "intentional" object of my "intentional state" is the mental chair I have in mind. (Yet another term for intentionality has been "aboutness" or "representationality": thoughts are always <i>about</i> something; they are (mental) "representations" <i>of</i> something; but that something is what it is that the thinker has in mind, not whatever external object may or may not correspond to it.)</p>
<p>If this all sounds like skating over the surface of a problem rather than a real break-through, then the foregoing description has had its intended effect: No, the problem of intentionality is not the symbol grounding problem; nor is grounding symbols the solution to the problem of intentionality. The symbols inside an autonomous dynamical symbol system that is able to pass the robotic Turing Test are grounded, in that, unlike in the case of an ungrounded symbol system, they do not depend on the mediation of the mind of an external interpreter to connect them to the external objects that they are interpretable (by the interpreter) as being "about"; the connection is autonomous, direct, and unmediated. But <i>grounding is not meaning</i>. Grounding is an input/output performance function. Grounding connects the sensory inputs from external objects to internal symbols and states occurring within an autonomous sensorimotor system, guiding the system's resulting processing and output.</p>
<p>Meaning, in contrast, is something mental. But to try to put a halt to the name-game of proliferating nonexplanatory synonyms for the mind/body problem without solving it (or, worse, implying that there is more than one mind/body problem), let us cite just one more thing that requires no further explication: <i>feeling</i>. The only thing that distinguishes an internal state that merely has grounding from one that has meaning is that it <i>feels like something</i> to be in the meaning state, whereas it does not feel like anything to be in the merely grounded functional state. Grounding is a functional matter; feeling is a felt matter. And that is the real source of Brentano's vexed peekaboo relation between "intentionality" and its internal "intentional object": All mental states, in addition to being the functional states of an autonomous dynamical system, are also feeling states: Feelings are not merely "functed," as all other physical states are; feelings are also felt.</p>
<p>Hence feeling is the real mark of the mental. But the symbol grounding problem is not the same as the mind/body problem, let alone a solution to it. The mind/body problem is actually the feeling/function problem: Symbol-grounding touches only its functional component.</p>
<p><b>Note:</b> <i>This article is based on an entry originally published in Nature/Macmillan Encyclopedia of Cognitive Science that has since been revised by the author and the Wikipedia community</i></p>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=11" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li>Blondin Masse, A, G. Chicoisne, Y. Gargouri, S. Harnad, O. Picard, O. Marcotte (2008) <a href="http://arxiv.org/abs/0806.3710" class="external text" title="http://arxiv.org/abs/0806.3710" rel="nofollow">How Is Meaning Grounded in Dictionary Definitions?</a> <i>TextGraphs-3 Workshop, 22nd International Conference on Computational Linguistics, Coling 2008</i>, Manchester, 18-22 August, 2008</li>
<li>Cangelosi, A. &amp; Harnad, S. (2001) <a href="http://cogprints.org/2036/" class="external text" title="http://cogprints.org/2036/" rel="nofollow">The Adaptive Advantage of Symbolic Theft Over Sensorimotor Toil: Grounding Language in Perceptual Categories.</a> <i>Evolution of Communication</i> 4(1) 117-142.</li>
<li>Cangelosi, A.; Greco, A.; Harnad, S. <a href="http://cogprints.org/2132/" class="external text" title="http://cogprints.org/2132/" rel="nofollow">From robotic toil to symbolic theft: grounding transfer from entry-level to higher-level categories.</a> <i>Connection Science</i>12(2) 143-62.</li>
<li>Fodor, J. A. (1975) <i>The language of thought</i>. New York: Thomas Y. Crowell</li>
<li>Frege, G. (1952/1892). On sense and reference. In P. Geach and M. Black, Eds., <i>Translations of the Philosophical Writings of Gottlob Frege</i>. Oxford: Blackwell</li>
<li>Harnad, S. (1990) <a href="http://cogprints.org/3106/" class="external text" title="http://cogprints.org/3106/" rel="nofollow">The Symbol Grounding Problem.</a> <i>Physica D</i> 42: 335-346.</li>
<li>Harnad, S. (1992) <a href="http://eprints.ecs.soton.ac.uk/6464/" class="external text" title="http://eprints.ecs.soton.ac.uk/6464/" rel="nofollow">There Is Only One Mind/Body Problem</a>. Symposium on the Perception of Intentionality, XXV World Congress of Psychology, Brussels, Belgium, July 1992 <i>International Journal of Psychology</i> 27: 521</li>
<li>Harnad, S. (1994) <a href="http://cogprints.org/1592/" class="external text" title="http://cogprints.org/1592/" rel="nofollow">Computation Is Just Interpretable Symbol Manipulation: Cognition Isn't.</a> <i>Minds and Machines</i> 4:379-390 (Special Issue on "What Is Computation")</li>
<li>Harnad, S. (1995) <a href="http://eprints.ecs.soton.ac.uk/3347/" class="external text" title="http://eprints.ecs.soton.ac.uk/3347/" rel="nofollow">Why and How We Are Not Zombies.</a> <i>Journal of Consciousness Studies</i> 1: 164-167.</li>
<li>Harnad, S. (2000) <a href="http://cogprints.org/2615/" class="external text" title="http://cogprints.org/2615/" rel="nofollow">Minds, Machines and Turing: The Indistinguishability of Indistinguishables</a>. <i>Journal of Logic, Language, and Information</i> 9(4): 425-445. (Special Issue on "Alan Turing and Artificial Intelligence")</li>
<li>Harnad, S. (2001a) <a href="http://cogprints.org/4023/" class="external text" title="http://cogprints.org/4023/" rel="nofollow">Minds, Machines and Searle II: What's Wrong and Right About Searle's Chinese Room Argument?</a> In: M. Bishop &amp; J. Preston (eds.) <i>Essays on Searle's Chinese Room Argument</i>. Oxford University Press.</li>
<li>Harnad, S. (2001b) <a href="http://cogprints.org/1624/" class="external text" title="http://cogprints.org/1624/" rel="nofollow">No Easy Way Out.</a> <i>The Sciences</i> 41(2) 36-42.</li>
<li>Harnad, Stevan (2001a) <a href="http://eprints.ecs.soton.ac.uk/5943/" class="external text" title="http://eprints.ecs.soton.ac.uk/5943/" rel="nofollow">Explaining the Mind: Problems, Problems</a>. <i>The Sciences</i> 41: 36-42.</li>
<li>Harnad, Stevan (2001b) <a href="http://cogprints.org/2130/" class="external text" title="http://cogprints.org/2130/" rel="nofollow">The Mind/Body Problem is the Feeling/Function Problem: Harnad on Dennett on Chalmers</a>. Technical Report. Department of Electronics and Computer Sciences. University of Southampton.</li>
<li>Harnad, S. (2003) <a href="http://eprints.ecs.soton.ac.uk/7718/" class="external text" title="http://eprints.ecs.soton.ac.uk/7718/" rel="nofollow">Can a Machine Be Conscious? How?.</a> <i>Journal of Consciousness Studies</i> 10(4-5): 69-75.</li>
<li>Harnad, S. (2005) <a href="http://eprints.ecs.soton.ac.uk/11725/" class="external text" title="http://eprints.ecs.soton.ac.uk/11725/" rel="nofollow">To Cognize is to Categorize: Cognition is categorization.</a> in Lefebvre, C. and Cohen, H., Eds. <i>Handbook of Categorization</i>. Elsevier.</li>
<li>Harnad, S. (2007) <a href="http://eprints.ecs.soton.ac.uk/7741/" class="external text" title="http://eprints.ecs.soton.ac.uk/7741/" rel="nofollow">The Annotation Game: On Turing (1950) on Computing, Machinery and Intelligence.</a> In: Epstein, Robert &amp; Peters, Grace (Eds.) <i>The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer</i>. Kluwer</li>
<li>Harnad, S. (2006) <a href="http://eprints.ecs.soton.ac.uk/12092/" class="external text" title="http://eprints.ecs.soton.ac.uk/12092/" rel="nofollow">Cohabitation: Computation at 70 Cognition at 20.</a> In Dedrick, D., Eds. <i>Essays in Honour of Zenon Pylyshyn</i>.</li>
<li><a href="http://www.macdorman.com" class="external text" title="http://www.macdorman.com" rel="nofollow">MacDorman, Karl F.</a> (1999). Grounding symbols through sensorimotor integration. Journal of the Robotics Society of Japan, 17(1), 20-24. <a href="http://www.macdorman.com/kfm/writings/pubs/MacDorman1999GroundingSymbolsSMInteg.pdf" class="external text" title="http://www.macdorman.com/kfm/writings/pubs/MacDorman1999GroundingSymbolsSMInteg.pdf" rel="nofollow">Online version</a></li>
<li>Pylyshyn, Z. W. (1984) <i>Computation and cognition</i>. Cambridge MA: MIT/Bradford</li>
<li>Searle, John. R. (1980) <a href="http://www.bbsonline.org/documents/a/00/00/04/84/index.html" class="external text" title="http://www.bbsonline.org/documents/a/00/00/04/84/index.html" rel="nofollow">Minds, brains, and programs.</a> <i>Behavioral and Brain Sciences</i> 3(3): 417-457</li>
<li>Taddeo, Mariarosaria &amp; <a href="/wiki/Luciano_Floridi" title="Luciano Floridi">Floridi, Luciano</a> (2005). The symbol grounding problem: A critical review of fifteen years of research. <i>Journal of Experimental and Theoretical Artificial Intelligence, 17</i>(4), 419-445. <a href="http://web.comlab.ox.ac.uk/oucl/research/areas/ieg/research_reports/ieg_rr210605.pdf#search=%22taddeo%20symbol%20grounding%20problem%2" class="external text" title="http://web.comlab.ox.ac.uk/oucl/research/areas/ieg/research_reports/ieg_rr210605.pdf#search=%22taddeo%20symbol%20grounding%20problem%2" rel="nofollow">Online version</a></li>
<li>Turing, A.M. (1950) <a href="http://cogprints.ecs.soton.ac.uk/archive/00000499/" class="external text" title="http://cogprints.ecs.soton.ac.uk/archive/00000499/" rel="nofollow">Computing Machinery and Intelligence.</a> <i>Mind</i> 49 433-460 [Reprinted in <i>Minds and machines</i>. A. Anderson (ed.), Engelwood Cliffs NJ: Prentice Hall, 1964.]</li>
</ul>
<p><a name="Footnotes" id="Footnotes"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=12" title="Edit section: Footnotes">edit</a>]</span> <span class="mw-headline">Footnotes</span></h2>
<div class="references-small">
<ol class="references">
<li id="cite_note-0"><b><a href="#cite_ref-0" title="">^</a></b> Cf. <a href="/wiki/Anti-psychologism" title="Anti-psychologism">anti-psychologism</a>, <a href="/wiki/Psychologism" title="Psychologism">psychologism</a>, <a href="/wiki/Mentalism" title="Mentalism">mentalism</a>, <a href="/wiki/Intuitionism" title="Intuitionism">intuitionism</a>, <a href="/wiki/Constructivism" title="Constructivism">constructivism</a>, <a href="/wiki/Anti-realism" title="Anti-realism">anti-realism</a>, <a href="/wiki/Realism" title="Realism">realism</a></li>
<li id="cite_note-1"><b><a href="#cite_ref-1" title="">^</a></b> This mental process may learn a lesson from the <a href="/wiki/Information_retrieval" title="Information retrieval">information retrieval</a> process without degenerating into radical <a href="/wiki/Cognitivism" title="Cognitivism">cognitivism</a> and <a href="/wiki/Computationalism" title="Computationalism" class="mw-redirect">computationalism</a> as per the reductionist tradition.</li>
<li id="cite_note-2"><b><a href="#cite_ref-2" title="">^</a></b> Or, "imputed" as read below the dotted baseline of the <a href="/wiki/Triangle_of_reference" title="Triangle of reference">triangle of reference</a> since 1923.</li>
<li id="cite_note-3"><b><a href="#cite_ref-3" title="">^</a></b> This is exactly the <a href="/wiki/Causal_theory_of_reference" title="Causal theory of reference">causal</a>, <a href="/w/index.php?title=Contextual_theory_of_reference&amp;action=edit&amp;redlink=1" class="new" title="Contextual theory of reference (page does not exist)">contextual theory of reference</a> that <a href="/wiki/C._K._Ogden" title="C. K. Ogden" class="mw-redirect">Ogden</a> &amp; <a href="/wiki/I._A._Richards" title="I. A. Richards">Richards</a> packed in <i><a href="/wiki/The_Meaning_of_Meaning" title="The Meaning of Meaning">The Meaning of Meaning</a></i> (1923).</li>
<li id="cite_note-4"><b><a href="#cite_ref-4" title="">^</a></b> Cf. <a href="/wiki/Semantic_externalism" title="Semantic externalism">semantic externalism</a> as claimed in "The Meaning of 'Meaning'" of <i>Mind, Language and Reality</i> (1975) by <a href="/wiki/Hilary_Putnam" title="Hilary Putnam">Putnam</a> who argues: "Meanings just ain't in the head." Now he and <a href="/wiki/Michael_Dummett" title="Michael Dummett">Dummett</a> seem to favor <a href="/wiki/Anti-realism" title="Anti-realism">anti-realism</a> in favor of <a href="/wiki/Intuitionism" title="Intuitionism">intuitionism</a>, <a href="/wiki/Psychologism" title="Psychologism">psychologism</a>, <a href="/wiki/Constructivism" title="Constructivism">constructivism</a> and <a href="/wiki/Contextualism" title="Contextualism">contextualism</a>.</li>
</ol>
</div>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Symbol_grounding&amp;action=edit&amp;section=13" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<table cellspacing="0" cellpadding="0" class="multicol" style="background:transparent; width:100%;">
<tr>
<td align="left" valign="top">
<ul>
<li><a href="/wiki/Categorical_Perception" title="Categorical Perception" class="mw-redirect">Categorical Perception</a></li>
<li><a href="/wiki/Chinese_Room" title="Chinese Room" class="mw-redirect">Chinese Room</a></li>
<li><a href="/wiki/Communicative_action" title="Communicative action">Communicative action</a></li>
<li><a href="/wiki/Consciousness" title="Consciousness">Consciousness</a></li>
<li><a href="/wiki/Formal_language" title="Formal language">Formal language</a></li>
<li><a href="/wiki/Formal_system" title="Formal system">Formal system</a></li>
<li><a href="/wiki/Functionalism_(philosophy_of_mind)" title="Functionalism (philosophy of mind)">Functionalism</a></li>
</ul>
</td>
<td align="left" valign="top">
<ul>
<li><a href="/wiki/Hermeneutics" title="Hermeneutics">Hermeneutics</a></li>
<li><a href="/wiki/Interpretation" title="Interpretation">Interpretation</a></li>
<li><a href="/wiki/Physical_symbol_system" title="Physical symbol system">Physical symbol system</a></li>
<li><a href="/wiki/Pragmatics" title="Pragmatics">Pragmatics</a></li>
<li><a href="/wiki/Semantics" title="Semantics">Semantics</a></li>
<li><a href="/wiki/Semeiotic" title="Semeiotic">Semeiotic</a></li>
<li><a href="/wiki/Semiosis" title="Semiosis">Semiosis</a></li>
</ul>
</td>
<td align="left" valign="top">
<ul>
<li><a href="/wiki/Semiotics" title="Semiotics">Semiotics</a></li>
<li><a href="/wiki/Sign" title="Sign">Sign</a></li>
<li><a href="/wiki/Sign_relation" title="Sign relation">Sign relation</a></li>
<li><a href="/wiki/Situated_cognition" title="Situated cognition">Situated cognition</a></li>
<li><a href="/wiki/Syntax" title="Syntax">Syntax</a></li>
<li><a href="/wiki/Turing_machine" title="Turing machine">Turing machine</a></li>
</ul>
</td>
</tr>
</table>


<!-- 
NewPP limit report
Preprocessor node count: 360/1000000
Post-expand include size: 5531/2048000 bytes
Template argument size: 1592/2048000 bytes
Expensive parser function count: 0/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:3446949-0!1!0!default!!en!2 and timestamp 20090406154035 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Symbol_grounding">http://en.wikipedia.org/wiki/Symbol_grounding</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Symbolism" title="Category:Symbolism">Symbolism</a></span> | <span dir='ltr'><a href="/wiki/Category:Philosophy_of_mind" title="Category:Philosophy of mind">Philosophy of mind</a></span> | <span dir='ltr'><a href="/wiki/Category:Semantics" title="Category:Semantics">Semantics</a></span></div><div id="mw-hidden-catlinks" class="mw-hidden-cats-hidden">Hidden categories:&#32;<span dir='ltr'><a href="/wiki/Category:All_articles_needing_style_editing" title="Category:All articles needing style editing">All articles needing style editing</a></span> | <span dir='ltr'><a href="/wiki/Category:Wikipedia_articles_needing_style_editing_from_November_2008" title="Category:Wikipedia articles needing style editing from November 2008">Wikipedia articles needing style editing from November 2008</a></span> | <span dir='ltr'><a href="/wiki/Category:Articles_needing_more_viewpoints" title="Category:Articles needing more viewpoints">Articles needing more viewpoints</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Symbol_grounding" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Symbol_grounding" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Symbol_grounding&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Symbol_grounding&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Symbol_grounding" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content ‚Äî the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Symbol_grounding" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Symbol_grounding" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Symbol_grounding&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Symbol_grounding&amp;oldid=272414253" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Symbol_grounding&amp;id=272414253">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-hu"><a href="http://hu.wikipedia.org/wiki/A_szimb%C3%B3lum-lehorgonyoz%C3%A1s_probl%C3%A9m%C3%A1ja">Magyar</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%B3%E3%83%9C%E3%83%AB%E3%82%B0%E3%83%A9%E3%82%A6%E3%83%B3%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E5%95%8F%E9%A1%8C">Êó•Êú¨Ë™û</a></li>
				<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Symbolin_maadoittamisen_ongelma">Suomi</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 22 February 2009, at 03:54.</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv162 in 0.320 secs. --></body></html>
