<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en" dir="ltr">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<meta http-equiv="Content-Style-Type" content="text/css" />
		<meta name="generator" content="MediaWiki 1.15alpha" />
		<meta name="keywords" content="Semantic relatedness,Dijkstra&#039;s algorithm,Educational Testing Service,Google search,Keyword (internet search),Latent semantic analysis,Open Directory Project,Pointwise Mutual Information,Self-organizing map,Semantic differential,Semantic similarity" />
		<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Semantic_relatedness&amp;action=edit" />
		<link rel="edit" title="Edit this page" href="/w/index.php?title=Semantic_relatedness&amp;action=edit" />
		<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
		<link rel="shortcut icon" href="/favicon.ico" />
		<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)" />
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html" />
		<link rel="alternate" type="application/rss+xml" title="Wikipedia RSS Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=rss" />
		<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom Feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom" />
		<title>Semantic relatedness - Wikipedia, the free encyclopedia</title>
		<link rel="stylesheet" href="/skins-1.5/common/shared.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/common/commonPrint.css?207xx" type="text/css" media="print" />
		<link rel="stylesheet" href="/skins-1.5/monobook/main.css?207xx" type="text/css" media="screen" />
		<link rel="stylesheet" href="/skins-1.5/chick/main.css?207xx" type="text/css" media="handheld" />
		<!--[if lt IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE50Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 5.5000]><link rel="stylesheet" href="/skins-1.5/monobook/IE55Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 6]><link rel="stylesheet" href="/skins-1.5/monobook/IE60Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<!--[if IE 7]><link rel="stylesheet" href="/skins-1.5/monobook/IE70Fixes.css?207xx" type="text/css" media="screen" /><![endif]-->
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Common.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Print.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="print" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Handheld.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" media="handheld" />
		<link rel="stylesheet" href="/w/index.php?title=MediaWiki:Monobook.css&amp;usemsgcache=yes&amp;ctype=text%2Fcss&amp;smaxage=2678400&amp;action=raw&amp;maxage=2678400" type="text/css" />
		<link rel="stylesheet" href="/w/index.php?title=-&amp;action=raw&amp;maxage=2678400&amp;gen=css" type="text/css" />
		<!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?207xx"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->

		<script type= "text/javascript">/*<![CDATA[*/
		var skin = "monobook";
		var stylepath = "/skins-1.5";
		var wgArticlePath = "/wiki/$1";
		var wgScriptPath = "/w";
		var wgScript = "/w/index.php";
		var wgVariantArticlePath = false;
		var wgActionPaths = {};
		var wgServer = "http://en.wikipedia.org";
		var wgCanonicalNamespace = "";
		var wgCanonicalSpecialPageName = false;
		var wgNamespaceNumber = 0;
		var wgPageName = "Semantic_relatedness";
		var wgTitle = "Semantic relatedness";
		var wgAction = "view";
		var wgArticleId = "8285409";
		var wgIsArticle = true;
		var wgUserName = null;
		var wgUserGroups = null;
		var wgUserLanguage = "en";
		var wgContentLanguage = "en";
		var wgBreakFrames = false;
		var wgCurRevisionId = 284841511;
		var wgVersion = "1.15alpha";
		var wgEnableAPI = true;
		var wgEnableWriteAPI = true;
		var wgSeparatorTransformTable = ["", ""];
		var wgDigitTransformTable = ["", ""];
		var wgMWSuggestTemplate = "http://en.wikipedia.org/w/api.php?action=opensearch\x26search={searchTerms}\x26namespace={namespaces}\x26suggest";
		var wgDBname = "enwiki";
		var wgSearchNamespaces = [0];
		var wgMWSuggestMessages = ["with suggestions", "no suggestions"];
		var wgRestrictionEdit = [];
		var wgRestrictionMove = [];
		/*]]>*/</script>

		<script type="text/javascript" src="/skins-1.5/common/wikibits.js?207xx"><!-- wikibits js --></script>
		<!-- Head Scripts -->
		<script type="text/javascript" src="/skins-1.5/common/ajax.js?207xx"></script>
		<script type="text/javascript" src="/skins-1.5/common/mwsuggest.js?207xx"></script>
<script type="text/javascript">/*<![CDATA[*/
var wgNotice='';var wgNoticeLocal='';
/*]]>*/</script>		<script type="text/javascript" src="http://upload.wikimedia.org/centralnotice/wikipedia/en/centralnotice.js?207xx"></script>
		<script type="text/javascript" src="/w/index.php?title=-&amp;action=raw&amp;gen=js&amp;useskin=monobook"><!-- site js --></script>
	</head>
<body class="mediawiki ltr ns-0 ns-subject page-Semantic_relatedness skin-monobook">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type='text/javascript'>if (wgNotice != '') document.writeln(wgNotice);</script></div>		<h1 id="firstHeading" class="firstHeading">Semantic relatedness</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/Semantic_similarity" title="Semantic similarity">Semantic similarity</a></div>
<p>Computational Measures of <b>Semantic Relatedness</b> are <a href="http://cwl-projects.cogsci.rpi.edu/msr/" class="external text" title="http://cwl-projects.cogsci.rpi.edu/msr/" rel="nofollow">publicly available</a> means for approximating the relative meaning of words/documents. These have been used for essay-grading by the <a href="/wiki/Educational_Testing_Service" title="Educational Testing Service">Educational Testing Service</a>, search engine technology, predicting which links people are likely to click on, etc.</p>
<ul>
<li>LSA (<a href="/wiki/Latent_semantic_analysis" title="Latent semantic analysis">Latent semantic analysis</a>) (+) vector-based, adds vectors to measure multi-word terms; (-) non-incremental vocabulary, long pre-processing times</li>
<li>PMI (<a href="/wiki/Pointwise_Mutual_Information" title="Pointwise Mutual Information" class="mw-redirect">Pointwise Mutual Information</a>) (+) large vocab, because it uses any search engine (like Google); (-) cannot measure relatedness between whole sentences or documents</li>
<li>SOC-PMI (<a href="/w/index.php?title=Second_Order_Co-occurrence_PMI&amp;action=edit&amp;redlink=1" class="new" title="Second Order Co-occurrence PMI (page does not exist)">Second Order Co-occurrence PMI</a>) (+) sort lists of important neighbor words from a large corpus; (-) cannot measure relatedness between whole sentences or documents</li>
<li>GLSA (Generalized Latent Semantic Analysis) (+) vector-based, adds vectors to measure multi-word terms; (-) non-incremental vocabulary, long pre-processing times</li>
<li>ICAN (Incremental Construction of an Associative Network) (+) incremental, network-based measure, good for spreading activation, accounts for second-order relatedness; (-) cannot measure relatedness between multi-word terms, long pre-processing times</li>
<li>NGD (Normalized Google Distance; see below) (+) large vocab, because it uses any search engine (like Google); (-) cannot measure relatedness between whole sentences or documents</li>
<li><a href="/wiki/WordNet" title="WordNet">WordNet</a>: (+) humanly constructed; (-) humanly constructed (not automatically learned), cannot measure relatedness between multi-word term, non-incremental vocabulary</li>
<li><a href="http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf" class="external text" title="http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf" rel="nofollow">ESA (Explicit Semantic Analysis)</a> based on <a href="/wiki/Wikipedia" title="Wikipedia">Wikipedia</a> and the <a href="/wiki/Open_Directory_Project" title="Open Directory Project">ODP</a></li>
<li><a href="http://doi.acm.org/10.1145/1232425.1232448" class="external text" title="http://doi.acm.org/10.1145/1232425.1232448" rel="nofollow">n° of Wikipedia (noW)</a>, inspired by the game <a href="http://chronicle.com/wiredcampus/article/3041/six-degrees-of-wikipedia" class="external text" title="http://chronicle.com/wiredcampus/article/3041/six-degrees-of-wikipedia" rel="nofollow">Six Degree of Wikipedia</a>, is a distance metric based on the hierarchical structure of Wikipedia. A directed-acyclic graph is first constructed and later, <a href="/wiki/Dijkstra%27s_algorithm" title="Dijkstra's algorithm">Dijkstra's shortest path algorithm</a> is employed to determine the noW value between two terms as the geodesic distance between the corresponding topics (i.e. nodes) in the graph. Demo is available <a href="http://explorer.csse.uwa.edu.au/research/algorithm_now.pl" class="external text" title="http://explorer.csse.uwa.edu.au/research/algorithm_now.pl" rel="nofollow">here</a>.</li>
<li><a href="http://www.cogsci.rpi.edu/vekslv/pubs/pp718-veksler.pdf" class="external text" title="http://www.cogsci.rpi.edu/vekslv/pubs/pp718-veksler.pdf" rel="nofollow">VGEM</a> (Vector Generation of an Explicitly-defined Multidimensional Semantic Space) (+) incremental vocab, can compare multi-word terms (-) performance depends on choosing specific dimensions</li>
<li><a href="http://www.cogsci.rpi.edu/cogworks/publications/270_BLOSSOM_final.pdf" class="external text" title="http://www.cogsci.rpi.edu/cogworks/publications/270_BLOSSOM_final.pdf" rel="nofollow">BLOSSOM</a> (Best path Length On a Semantic Self-Organizing Map) (+) uses a <a href="/wiki/Self-organizing_map" title="Self-organizing map">Self Organizing Map</a> to reduce high dimensional spaces, can use different vector representations (VGEM or word-document matrix), provides 'concept path linking' from one word to another (-) highly experimental, requires nontrivial SOM calculation</li>
</ul>
<table id="toc" class="toc" summary="Contents">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1"><a href="#Semantic_similarity_measures"><span class="tocnumber">1</span> <span class="toctext">Semantic similarity measures</span></a>
<ul>
<li class="toclevel-2"><a href="#SimRank"><span class="tocnumber">1.1</span> <span class="toctext">SimRank</span></a></li>
<li class="toclevel-2"><a href="#Google_distance"><span class="tocnumber">1.2</span> <span class="toctext">Google distance</span></a></li>
<li class="toclevel-2"><a href="#SOC-PMI"><span class="tocnumber">1.3</span> <span class="toctext">SOC-PMI</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">2</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">3</span> <span class="toctext">References</span></a>
<ul>
<li class="toclevel-2"><a href="#Google_distance_references"><span class="tocnumber">3.1</span> <span class="toctext">Google distance references</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">4</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="Semantic_similarity_measures" id="Semantic_similarity_measures"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=1" title="Edit section: Semantic similarity measures">edit</a>]</span> <span class="mw-headline">Semantic similarity measures</span></h2>
<p><a name="SimRank" id="SimRank"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=2" title="Edit section: SimRank">edit</a>]</span> <span class="mw-headline">SimRank</span></h3>
<div class="rellink noprint relarticle mainarticle">Main article: <a href="/wiki/SimRank" title="SimRank">SimRank</a></div>
<p><a name="Google_distance" id="Google_distance"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=3" title="Edit section: Google distance">edit</a>]</span> <span class="mw-headline">Google distance</span></h3>
<p><b>Google distance</b> is a measure of semantic interrelatedness derived from the number of hits returned by the <a href="/wiki/Google_search" title="Google search">Google search engine</a> for a given <a href="/wiki/Set_(computer_science)" title="Set (computer science)">set</a> of <a href="/wiki/Keyword_(internet_search)" title="Keyword (internet search)" class="mw-redirect">keywords</a>. Keywords with the same or similar meanings in a natural language sense tend to be "close" in units of Google distance, while words with dissimilar meanings tend to be farther apart.</p>
<p>Specifically, the <i>normalized Google distance</i> between two search terms <i>x</i> and <i>y</i> is</p>
<dl>
<dd><img class="tex" alt="
\operatorname{NGD}(x,y) = \frac{\max\{\log f(x), \log f(y)\} - \log f(x,y)}
{\log M - \min\{\log f(x), \log f(y)\}}
" src="http://upload.wikimedia.org/math/6/9/6/69612b36f42cfd910edc461586731dcb.png" /></dd>
</dl>
<p>where <i>M</i> is the total number of web pages searched by Google; <i>f</i>(<i>x</i>) and <i>f</i>(<i>y</i>) are the number of hits for search terms <i>x</i> and <i>y</i>, respectively; and <i>f</i>(<i>x</i>,&#160;<i>y</i>) is the number of web pages on which both <i>x</i> and <i>y</i> occur.</p>
<p>If the two search terms <i>x</i> and <i>y</i> never occur together on the same web page, but do occur separately, the normalized Google distance between them is infinite. If both terms always occur together, their NGD is zero.</p>
<p><a name="SOC-PMI" id="SOC-PMI"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=4" title="Edit section: SOC-PMI">edit</a>]</span> <span class="mw-headline">SOC-PMI</span></h3>
<p>Second Order Co-occurrence PMI (SOC-PMI) (Islam and Inkpen, 2006) word similarity method uses Pointwise Mutual Information to sort lists of important neighbor words of the two target words from a large corpus. PMI-IR used AltaVista's Advanced Search query syntax to calculate probabilities. Note that the ``NEAR" search operator of AltaVista is an essential operator in the PMI-IR method. However, it is no longer in use in AltaVista; this means that, from the implementation point of view, it is not possible to use the PMI-IR method in the same form in new systems. In any case, from the algorithmic point of view, the advantage of using SOC-PMI is that it can calculate the similarity between two words that do not co-occur frequently, because they co-occur with the same neighboring words. We used the British National Corpus (BNC) as a source of frequencies and contexts. The method considers the words that are common in both lists and aggregate their PMI values (from the opposite list) to calculate the relative semantic similarity. We define the <i>pointwise mutual information</i> function for only those words having <span class="texhtml"><i>f</i><sup><i>b</i></sup>(<i>t</i><sub><i>i</i></sub>,<i>w</i>) &gt; 0</span>,</p>
<dl>
<dd><img class="tex" alt="
 f^{pmi}(t_{i},w)=\log_{2}\frac{f^{b}(t_{i},w)\times m}{f^{t}(t_{i})f^{t}(w)},
" src="http://upload.wikimedia.org/math/d/4/1/d412571fe5168246ec308195a7954523.png" /></dd>
</dl>
<p>where <span class="texhtml"><i>f</i><sup><i>t</i></sup>(<i>t</i><sub><i>i</i></sub>)</span> tells us how many times the type <span class="texhtml"><i>t</i><sub><i>i</i></sub></span> appeared in the entire corpus, <span class="texhtml"><i>f</i><sup><i>b</i></sup>(<i>t</i><sub><i>i</i></sub>,<i>w</i>)</span> tells us how many times word <span class="texhtml"><i>t</i><sub><i>i</i></sub></span> appeared with word <span class="texhtml"><i>w</i></span> in a context window and <span class="texhtml"><i>m</i></span> is total number of tokens in the corpus. Now, for word <span class="texhtml"><i>w</i></span>, we define a set of words, <span class="texhtml"><i>X</i><sup><i>w</i></sup></span>, sorted in descending order by their PMI values with <span class="texhtml"><i>w</i></span> and taken the top-most <span class="texhtml">β</span> words having <span class="texhtml"><i>f</i><sup><i>p</i><i>m</i><i>i</i></sup>(<i>t</i><sub><i>i</i></sub>,<i>w</i>) &gt; 0</span>. \par <img class="tex" alt="X^{w}=\{X_{i}^{w}\}" src="http://upload.wikimedia.org/math/c/0/8/c08f5f5c82e6be53b34d9b414cbbf40a.png" />, where <img class="tex" alt="i=1, 2, \cdots ,\beta" src="http://upload.wikimedia.org/math/2/a/b/2ab9ad7c2c65b4634898d79cc771ac6d.png" /> and <img class="tex" alt="f^{pmi}(t_{1}, w)\geq f^{pmi}(t_{2}, w)\geq \cdots f^{pmi}(t_{\beta-1}, w)\geq f^{pmi}(t_{\beta}, w)" src="http://upload.wikimedia.org/math/6/8/0/6808e5174ddde6002a17db6a5b4e0f10.png" /></p>
<p>A rule of thumb is used to choose the value of <span class="texhtml">β</span> We define the <i><span class="texhtml">β</span>-PMI summation</i> function of a word with respect to another word. The <i><span class="texhtml">β</span>-PMI summation</i> function for word <span class="texhtml"><i>w</i><sub>1</sub></span> with respect to word <span class="texhtml"><i>w</i><sub>2</sub></span> is: <img class="tex" alt="
f(w_{1},w_{2},\beta)=\sum_{i=1}^{\beta}(f^{pmi}(X_{i}^{w_{1}},w_{2}))^{\gamma}
" src="http://upload.wikimedia.org/math/0/7/9/0793bbbf40afba7bc9a42720a2850af4.png" /> where, <img class="tex" alt="f^{pmi}(X_{i}^{w_{1}},w_{2})&gt;0" src="http://upload.wikimedia.org/math/4/b/8/4b87e5cf453106d812a03167213a2544.png" /> which sums all the positive PMI values of words in the set <img class="tex" alt="X^{w_{2}}" src="http://upload.wikimedia.org/math/1/e/6/1e685b995883cc3ad0930a19d89ffc7e.png" /> also common to the words in the set <img class="tex" alt="X^{w_{1}}" src="http://upload.wikimedia.org/math/b/c/6/bc61a905f7d815d0b92a854830e3b75b.png" />. In other words, this function actually aggregates the positive PMI values of all the semantically close words of <span class="texhtml"><i>w</i><sub>2</sub></span> which are also common in <span class="texhtml"><i>w</i><sub>1</sub></span>'s list. <span class="texhtml">γ</span> should have a value greater than 1. So, the <i><span class="texhtml">β</span>-PMI summation</i> function for word <span class="texhtml"><i>w</i><sub>1</sub></span> with respect to word <span class="texhtml"><i>w</i><sub>2</sub></span> having <span class="texhtml">β = β<sub>1</sub></span> and the <i><span class="texhtml">β</span>-PMI summation</i> function for word <span class="texhtml"><i>w</i><sub>2</sub></span> with respect to word <span class="texhtml"><i>w</i><sub>1</sub></span> having <span class="texhtml">β = β<sub>2</sub></span> are <img class="tex" alt="
f(w_{1},w_{2},\beta_{1})=\sum_{i=1}^{\beta_{1}}(f^{pmi}(X_{i}^{w_{1}},w_{2}))^{\gamma}
" src="http://upload.wikimedia.org/math/c/c/1/cc11ccb13fb9563da03697ca90b17156.png" /> and</p>
<p><img class="tex" alt="
f(w_{2},w_{1},\beta_{2})=\sum_{i=1}^{\beta_{2}}(f^{pmi}(X_{i}^{w_{2}},w_{1}))^{\gamma}" src="http://upload.wikimedia.org/math/9/3/5/935859bc102c8661bb24bc431e0a6637.png" /> respectively.</p>
<p>Finally, we define the <i>semantic PMI similarity</i> function between the two words, <span class="texhtml"><i>w</i><sub>1</sub></span> and <span class="texhtml"><i>w</i><sub>2</sub></span>, <img class="tex" alt="
Sim(w_{1},w_{2})=\frac{f(w_{1},w_{2},\beta_{1})}{\beta_{1}}+\frac{f(w_{2},w_{1},\beta_{2})}{\beta_{2}}
" src="http://upload.wikimedia.org/math/d/7/1/d713d5bc97c16b238bfd4de67bb01e1c.png" /> We normalize the semantic word similarity, so that it provides a similarity score between <span class="texhtml">0</span> and <span class="texhtml">1</span> inclusively. The normalization of semantic similarity algorithm returns a normalized score of similarity between two words. It takes as arguments the two words, <span class="texhtml"><i>r</i><sub><i>i</i></sub></span> and <span class="texhtml"><i>s</i><sub><i>j</i></sub></span>, and a maximum value, <span class="texhtml">λ</span>, that is returned by the semantic similarity function, <i>Sim</i>(). It returns a similarity score between 0 and 1 inclusively. For example, the algorithm returns 0.986 for words <i>cemetery</i> and <i>graveyard</i> with <span class="texhtml">λ = 20</span> (for SOC-PMI method).</p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=5" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="/wiki/Semantic_differential" title="Semantic differential">Semantic differential</a></li>
</ul>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=6" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li>Cilibrasi, R. &amp; Vitanyi, P.M.B. (2006). Similarity of objects and the meaning of words. Proc. 3rd Conf. Theory and Applications of Models of Computation (TAMC), J.-Y. Cai, S. B. Cooper, and A. Li (Eds.), Lecture Notes in Computer Science, Vol. 3959, Springer-Verlag, Berlin.</li>
<li>Dumais, S. (2003). Data-driven approaches to information access. Cognitive Science, 27(3), 491-524.</li>
<li>Gabrilovich, E. and Markovitch, S. (2007). "Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis", Proceedings of The 20th International Joint Conference on Artificial Intelligence (IJCAI), Hyderabad, India, January 2007. <a href="http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf" class="external autonumber" title="http://www.cs.technion.ac.il/~gabr/papers/ijcai-2007-sim.pdf" rel="nofollow">[1]</a></li>
<li>Islam, A. and Inkpen, D. (2008). Semantic text similarity using corpus-based word similarity and string similarity. ACM Trans. Knowl. Discov. Data 2, 2 (Jul. 2008), 1-25. DOI= <a href="http://doi.acm.org/10.1145/1376815.1376819" class="external free" title="http://doi.acm.org/10.1145/1376815.1376819" rel="nofollow">http://doi.acm.org/10.1145/1376815.1376819</a></li>
<li>Islam, A. and Inkpen, D. (2006). Second Order Co-occurrence PMI for Determining the Semantic Similarity of Words, in Proceedings of the International Conference on Language Resources and Evaluation (LREC 2006), Genoa, Italy, pp. 1033-1038. <a href="http://www.site.uottawa.ca/~mdislam/publications/LREC_06_242.pdf" class="external autonumber" title="http://www.site.uottawa.ca/~mdislam/publications/LREC_06_242.pdf" rel="nofollow">[2]</a></li>
<li>Juvina, I., van Oostendorp, H., Karbor, P., &amp; Pauw, B. (2005). Towards modeling contextual information in web navigation. In B. G. Bara &amp; L. Barsalou &amp; M. Bucciarelli (Eds.), 27th Annual Meeting of the Cognitive Science Society, CogSci2005 (pp. 1078-1083). Austin, Tx: The Cognitive Science Society, Inc.</li>
<li>Kaur, I. &amp; Hornof, A.J. (2005). A Comparison of LSA, WordNet and PMI for Predicting User Click Behavior. Proceedings of the Conference on Human Factors in Computing, CHI 2005 (pp. 51-60).</li>
<li>Landauer, T. K., &amp; Dumais, S. T. (1997). A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104(2), 211-240.</li>
<li>Landauer, T. K., Foltz, P. W., &amp; Laham, D. (1998). Introduction to Latent Semantic Analysis. Discourse Processes, 25, 259-284.</li>
<li>Lee, M. D., Pincombe, B., &amp; Welsh, M. (2005). An empirical evaluation of models of text document similarity. In B. G. Bara &amp; L. Barsalou &amp; M. Bucciarelli (Eds.), 27th Annual Meeting of the Cognitive Science Society, CogSci2005 (pp. 1254-1259). Austin, Tx: The Cognitive Science Society, Inc.</li>
<li>Lemaire, B., &amp; Denhiére, G. (2004). Incremental construction of an associative network from a corpus. In K. D. Forbus &amp; D. Gentner &amp; T. Regier (Eds.), 26th Annual Meeting of the Cognitive Science Society, CogSci2004. Hillsdale, NJ: Lawrence Erlbaum Publisher.</li>
<li>Lindsey, R., Veksler, V.D., Grintsvayg, A., Gray, W.D. (2007). The Effects of Corpus Selection on Measuring Semantic Relatedness. Proceedings of the 8th International Conference on Cognitive Modeling, Ann Arbor, MI.</li>
<li>Pirolli, P. (2005). Rational analyses of information foraging on the Web. Cognitive Science, 29(3), 343-373.</li>
<li>Pirolli, P., &amp; Fu, W.-T. (2003). SNIF-ACT: A model of information foraging on the World Wide Web. Lecture Notes in Computer Science, 2702, 45-54.</li>
<li>Turney, P. (2001). Mining the Web for Synonyms: PMI versus LSA on TOEFL. In L. De Raedt &amp; P. Flach (Eds.), Proceedings of the Twelfth European Conference on Machine Learning (ECML-2001) (pp. 491-502). Freiburg, Germany.</li>
<li>Veksler, V.D. &amp; Gray, W.D. (2006). Test Case Selection for Evaluating Measures of Semantic Distance. Proceedings of the 28th Annual Meeting of the Cognitive Science Society, CogSci2006.</li>
<li>Wong, W., Liu, W. &amp; Bennamoun, M. (2008) Featureless Data Clustering. In: M. Song and Y. Wu; Handbook of Research on Text and Web Mining Technologies; IGI Global. [isbn: 978-1-59904-990-8] (the use of NGD and noW for term and URI clustering)</li>
</ul>
<p><a name="Google_distance_references" id="Google_distance_references"></a></p>
<h3><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=7" title="Edit section: Google distance references">edit</a>]</span> <span class="mw-headline">Google distance references</span></h3>
<ul>
<li>Rudi Cilibrasi and Paul Vitanyi (2004). <a href="http://arxiv.org/abs/cs.CL/0412098" class="external text" title="http://arxiv.org/abs/cs.CL/0412098" rel="nofollow">, The Google Similarity Distance, ArXiv.org</a> or <a href="http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/trans/tk/&amp;toc=comp/trans/tk/2007/03/k3toc.xml&amp;DOI=10.1109/TKDE.2007.48" class="external text" title="http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/trans/tk/&amp;toc=comp/trans/tk/2007/03/k3toc.xml&amp;DOI=10.1109/TKDE.2007.48" rel="nofollow">The Google Similarity Distance, IEEE Trans. Knowledge and Data Engineering, 19:3(2007), 370-383.</a>.</li>
<li><a href="http://www.newscientist.com/article.ns?id=dn6924" class="external text" title="http://www.newscientist.com/article.ns?id=dn6924" rel="nofollow">Google's search for meaning</a> at Newscientist.com.</li>
<li>Jan Poland and Thomas Zeugmann (2006), <a href="http://www-alg.ist.hokudai.ac.jp/~thomas/publications/dag_c2c_pz.pdf" class="external text" title="http://www-alg.ist.hokudai.ac.jp/~thomas/publications/dag_c2c_pz.pdf" rel="nofollow">Clustering the Google Distance with Eigenvectors and Semidefinite Programming</a></li>
<li>Aarti Gupta and Tim Oates (2007), <a href="http://dli.iiit.ac.in/ijcai/IJCAI-2007/PDF/IJCAI07-261.pdf" class="external text" title="http://dli.iiit.ac.in/ijcai/IJCAI-2007/PDF/IJCAI07-261.pdf" rel="nofollow">Using Ontologies and the Web to Learn Lexical Semantics</a> (Includes comparison of NGD to other algorithms.)</li>
<li>Wong, W., Liu, W. &amp; Bennamoun, M. (2007) Tree-Traversing Ant Algorithm for Term Clustering based on Featureless Similarities. In: Data Mining and Knowledge Discovery, Volume 15, Issue 3, Pages 349-381. [doi: 10.1007/s10618-007-0073-y] (the use of NGD for term clustering)</li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="/w/index.php?title=Semantic_relatedness&amp;action=edit&amp;section=8" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<ul>
<li><a href="http://cwl-projects.cogsci.rpi.edu/msr/" class="external text" title="http://cwl-projects.cogsci.rpi.edu/msr/" rel="nofollow">Measures of Semantic Relatedness</a></li>
<li><a href="http://wn-similarity.sourceforge.net" class="external text" title="http://wn-similarity.sourceforge.net" rel="nofollow">WordNet-Similarity</a>, an open source package for computing the similarity and relatedness of concepts found in WordNet</li>
</ul>


<!-- 
NewPP limit report
Preprocessor node count: 237/1000000
Post-expand include size: 734/2048000 bytes
Template argument size: 266/2048000 bytes
Expensive parser function count: 0/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:8285409-0!1!0!default!!en!2 and timestamp 20090419174550 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Semantic_relatedness">http://en.wikipedia.org/wiki/Semantic_relatedness</a>"</div>
			<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Categories</a>:&#32;<span dir='ltr'><a href="/wiki/Category:Computational_linguistics" title="Category:Computational linguistics">Computational linguistics</a></span> | <span dir='ltr'><a href="/wiki/Category:Statistical_distance_measures" title="Category:Statistical distance measures">Statistical distance measures</a></span></div></div>			<!-- end content -->
						<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
	
				 <li id="ca-nstab-main" class="selected"><a href="/wiki/Semantic_relatedness" title="View the content page [c]" accesskey="c">Article</a></li>
				 <li id="ca-talk"><a href="/wiki/Talk:Semantic_relatedness" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
				 <li id="ca-edit"><a href="/w/index.php?title=Semantic_relatedness&amp;action=edit" title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit this page</a></li>
				 <li id="ca-history"><a href="/w/index.php?title=Semantic_relatedness&amp;action=history" title="Past versions of this page [h]" accesskey="h">History</a></li>			</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Semantic_relatedness" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
	<div class='generated-sidebar portlet' id='p-navigation'>
		<h5>Navigation</h5>
		<div class='pBody'>
			<ul>
				<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
				<li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li>
				<li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content — the best of Wikipedia">Featured content</a></li>
				<li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
	<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/w/index.php" id="searchform"><div>
				<input type='hidden' name="title" value="Special:Search"/>
				<input id="searchInput" name="search" type="text" title="Search Wikipedia [f]" accesskey="f" value="" />
				<input type='submit' name="go" class="searchButton" id="searchGoButton"	value="Go" title="Go to a page with this exact name if one exists" />&nbsp;
				<input type='submit' name="fulltext" class="searchButton" id="mw-searchButton" value="Search" title="Search Wikipedia for this text" />
			</div></form>
		</div>
	</div>
	<div class='generated-sidebar portlet' id='p-interaction'>
		<h5>Interaction</h5>
		<div class='pBody'>
			<ul>
				<li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li>
				<li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="The list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
				<li id="n-contact"><a href="/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
				<li id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Donate" title="Support us">Donate to Wikipedia</a></li>
				<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Semantic_relatedness" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Semantic_relatedness" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="/wiki/Wikipedia:Upload" title="Upload files [u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="List of all special pages [q]" accesskey="q">Special pages</a></li>
				<li id="t-print"><a href="/w/index.php?title=Semantic_relatedness&amp;printable=yes" rel="alternate" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				<li id="t-permalink"><a href="/w/index.php?title=Semantic_relatedness&amp;oldid=284841511" title="Permanent link to this version of the page">Permanent link</a></li><li id="t-cite"><a href="/w/index.php?title=Special:Cite&amp;page=Semantic_relatedness&amp;id=284841511">Cite this page</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>Languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Normalisierte_Google-Distanz">Deutsch</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="/skins-1.5/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" /></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="/images/wikimedia-button.png" border="0" alt="Wikimedia Foundation"/></a></div>
			<ul id="f-list">
					<li id="lastmod"> This page was last modified on 19 April 2009, at 17:45 (UTC).</li>
					<li id="copyright">All text is available under the terms of the <a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class='internal' href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br /> Wikipedia&reg; is a registered trademark of the <a href="http://www.wikimediafoundation.org">Wikimedia Foundation, Inc.</a>, a U.S. registered <a class='internal' href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class='internal' href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br /></li>
					<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
					<li id="about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
					<li id="disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
</div>

		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
<!-- Served by srv203 in 0.061 secs. --></body></html>
